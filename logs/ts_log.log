2022-03-15T00:00:35,365 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:00:35,365 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:00:35,400 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:00:35,400 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:00:35,433 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220314235647646-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:00:35,433 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220314235647646-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:00:35,438 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220314235647646-shutdown.cfg",
  "modelCount": 1,
  "created": 1647316607646,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:00:35,438 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220314235647646-shutdown.cfg",
  "modelCount": 1,
  "created": 1647316607646,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:00:35,441 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220314235647646-shutdown.cfg
2022-03-15T00:00:35,441 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220314235647646-shutdown.cfg
2022-03-15T00:00:35,442 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220314235647646-shutdown.cfg validated successfully
2022-03-15T00:00:35,442 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220314235647646-shutdown.cfg validated successfully
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:00:35,552 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:00:35,552 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:00:35,552 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:00:35,558 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:00:35,558 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:00:35,558 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:00:35,558 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:00:35,558 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:00:35,558 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:00:35,558 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:00:35,558 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:00:35,558 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:00:35,558 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:00:35,558 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:00:35,558 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:00:35,558 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:00:35,558 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:00:35,558 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:00:35,558 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:00:35,561 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:00:35,561 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:00:35,686 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:00:35,686 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:00:35,686 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:00:35,686 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:00:35,702 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:00:35,702 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:00:35,702 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:00:35,702 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:00:35,709 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:00:35,709 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:00:36,079 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:00:36,079 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:00:36,130 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:36,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:224.21973419189453|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:36,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.21198654174805|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:36,134 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.3|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:36,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2671.109375|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:36,134 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5074.65625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:36,135 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.7|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647316836
2022-03-15T00:00:37,082 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,083 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,083 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]40571
2022-03-15T00:00:37,083 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,082 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,084 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,084 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]40570
2022-03-15T00:00:37,084 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,084 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,084 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,083 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,083 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]40575
2022-03-15T00:00:37,082 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,084 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,084 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]40577
2022-03-15T00:00:37,084 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,084 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]40573
2022-03-15T00:00:37,084 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,084 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,084 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,084 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,084 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]40572
2022-03-15T00:00:37,085 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,082 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,085 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,085 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,084 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,084 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,082 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:00:37,085 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,085 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,084 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]40576
2022-03-15T00:00:37,085 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,085 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]40574
2022-03-15T00:00:37,085 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,085 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,085 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,085 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:00:37,085 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:00:37,086 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,086 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:00:37,087 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:00:37,087 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:00:37,087 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:00:37,087 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:00:37,087 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:00:37,087 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:00:37,087 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:00:37,087 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:00:37,087 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:00:37,087 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:00:37,087 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:00:37,087 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:00:37,087 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:00:37,087 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:00:37,087 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:00:37,087 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:00:37,118 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837118
2022-03-15T00:00:37,118 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837118
2022-03-15T00:00:37,131 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:00:37,131 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:00:37,131 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:00:37,131 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:00:37,131 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:00:37,131 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:00:37,131 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:00:37,131 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647316837131
2022-03-15T00:00:37,131 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:00:37,133 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:00:37,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:00:37,153 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:00:37,153 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:00:37,153 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:00:37,198 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,198 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,198 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,199 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,201 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,201 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,201 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,201 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,207 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,207 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:00:37,207 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:00:37,208 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:00:37,208 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:00:37,208 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,208 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,207 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,209 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:00:37,209 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,209 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:00:37,209 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:00:37,209 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:00:37,209 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:00:37,209 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:00:37,212 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,212 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,208 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,212 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,208 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,213 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,213 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,218 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,218 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,219 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,219 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,224 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,224 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,225 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,225 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,230 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,230 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,231 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,231 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,256 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,256 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,257 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,257 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,257 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,257 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,257 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:00:37,258 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:00:37,258 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/9117c42cc31447a68267f3f79411e3be/handle.py", line 39, in initialize
2022-03-15T00:00:37,258 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.model = torch.load('/Users/changruimeng/Workspace/MovieRecommendation/model/model.pt')
2022-03-15T00:00:37,258 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 607, in load
2022-03-15T00:00:37,225 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,225 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,262 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:00:37,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:00:37,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:00:37,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:00:37,263 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:00:37,263 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:00:37,224 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,224 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,264 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,264 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,264 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,264 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,212 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:00:37,265 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:00:37,226 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,265 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:00:37,265 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:00:37,226 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,265 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:00:37,265 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,265 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,266 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,266 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,266 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:00:37,266 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:00:37,266 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:00:37,266 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:00:37,263 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:00:37,263 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:00:37,266 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:00:37,266 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:00:37,267 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:00:37,267 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:00:37,267 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:00:37,267 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:00:37,267 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:00:37,262 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,265 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,267 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:00:37,265 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:00:37,267 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,267 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,268 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,267 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,267 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,268 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,268 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,268 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,268 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,268 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,269 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:00:37,269 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:00:37,269 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:00:37,269 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:00:37,269 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:00:37,269 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:00:37,269 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:00:37,269 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:00:37,269 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:00:37,270 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:00:37,270 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:00:37,270 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:00:37,270 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:00:37,270 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:00:37,270 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:00:37,269 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:00:37,231 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,231 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,287 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,287 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,288 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,288 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,289 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:00:37,289 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:00:37,289 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:00:37,289 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:00:37,289 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:00:37,289 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:00:37,289 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2022-03-15T00:00:37,289 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:00:37,290 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:00:37,289 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:00:37,290 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:00:37,300 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:00:37,301 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:00:37,301 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:00:37,302 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,302 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:00:37,302 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:00:37,302 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,303 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:00:37,303 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:00:37,313 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,313 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:00:37,313 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:00:37,202 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,231 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,317 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:00:37,317 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,202 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,231 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:00:37,318 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,318 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,318 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,318 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,318 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,318 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:00:37,319 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,319 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:00:37,319 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:00:37,319 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:00:37,319 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:00:37,319 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:00:37,319 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:00:37,319 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:00:37,319 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:00:37,320 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:00:37,320 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:00:37,320 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:00:37,320 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:00:37,320 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:00:38,268 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:00:38,268 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:00:38,268 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:00:38,268 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:00:38,269 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:00:38,269 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:00:38,271 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:00:38,271 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:00:38,271 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:00:38,271 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:00:38,295 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:00:38,295 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:00:38,321 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:00:38,321 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:00:38,321 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:00:38,321 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:07:26,155 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:07:26,155 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:07:26,195 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:07:26,195 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:07:26,227 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000039019-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:07:26,227 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000039019-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:07:26,232 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000039019-shutdown.cfg",
  "modelCount": 1,
  "created": 1647316839019,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:07:26,232 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000039019-shutdown.cfg",
  "modelCount": 1,
  "created": 1647316839019,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:07:26,236 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000039019-shutdown.cfg
2022-03-15T00:07:26,236 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000039019-shutdown.cfg
2022-03-15T00:07:26,236 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000039019-shutdown.cfg validated successfully
2022-03-15T00:07:26,236 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000039019-shutdown.cfg validated successfully
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:07:26,351 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:07:26,351 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:07:26,351 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:07:26,357 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:07:26,357 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:07:26,357 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:07:26,357 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:07:26,357 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:07:26,357 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:07:26,357 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:07:26,357 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:07:26,357 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:07:26,357 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:07:26,357 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:07:26,357 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:07:26,357 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:07:26,357 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:07:26,357 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:07:26,357 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:07:26,359 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:07:26,359 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:07:26,505 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:07:26,505 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:07:26,505 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:07:26,505 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:07:26,506 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:07:26,506 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:07:26,507 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:07:26,507 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:07:26,507 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:07:26,507 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:07:26,906 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:07:26,906 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:07:26,950 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:26,951 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.89827346801758|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:26,951 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.533447265625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:26,951 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:26,951 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2715.515625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:26,951 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5027.6875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:26,951 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317246
2022-03-15T00:07:27,779 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,779 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,779 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,779 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,779 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41095
2022-03-15T00:07:27,779 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,779 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41099
2022-03-15T00:07:27,779 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41097
2022-03-15T00:07:27,779 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,779 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,780 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41101
2022-03-15T00:07:27,779 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,779 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:27,780 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,779 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,779 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41098
2022-03-15T00:07:27,779 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41096
2022-03-15T00:07:27,780 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41102
2022-03-15T00:07:27,780 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,780 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,780 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41100
2022-03-15T00:07:27,780 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,780 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,780 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,780 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,780 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:27,780 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:07:27,781 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,781 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:27,783 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:07:27,783 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:07:27,783 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:07:27,783 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:07:27,783 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:07:27,783 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:07:27,783 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:07:27,783 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:07:27,783 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:07:27,783 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:07:27,783 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:07:27,783 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:07:27,783 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:07:27,783 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:07:27,783 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:07:27,783 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:07:27,803 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247803
2022-03-15T00:07:27,803 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247803
2022-03-15T00:07:27,804 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:07:27,805 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:07:27,804 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,805 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:07:27,804 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,804 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317247804
2022-03-15T00:07:27,805 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:07:27,805 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:07:27,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:07:27,805 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:07:27,806 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:07:27,843 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,846 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,855 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,855 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,855 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,856 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,856 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,855 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:27,859 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,859 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,860 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,860 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,860 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,860 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,860 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,868 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,868 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,861 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,871 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,871 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,871 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,871 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,871 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,871 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,868 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,871 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,871 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,871 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,872 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,872 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,873 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,873 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,874 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,874 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,861 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,870 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,870 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,881 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,881 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,871 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,899 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,894 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,900 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,871 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,899 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,871 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,900 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,900 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,900 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,868 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,900 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,900 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,900 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,900 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,900 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,869 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,901 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,901 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,901 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,901 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,900 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,901 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,901 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,901 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,900 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,901 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,897 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,897 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,897 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,897 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,902 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,902 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,894 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,900 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,894 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,869 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,900 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,902 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,869 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:27,901 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,903 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,903 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,887 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,903 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,903 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,903 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,903 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,903 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,903 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,887 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:27,907 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,907 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:07:27,907 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:27,907 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/54eb36586184448298e3897ff2672c5b/handle.py", line 4, in <module>
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:07:27,908 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:07:27,921 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,922 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:07:27,922 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:07:27,922 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,922 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:07:27,922 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,922 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,922 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:07:27,922 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,923 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,923 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,923 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,923 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,923 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-03-15T00:07:27,923 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-03-15T00:07:27,923 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-03-15T00:07:27,923 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,923 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-03-15T00:07:27,923 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,932 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,932 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,932 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,932 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,932 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,932 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:07:27,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,942 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:27,943 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,943 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:27,943 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,943 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,943 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-03-15T00:07:27,943 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handle'
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,946 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,946 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,903 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,902 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,903 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,902 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,902 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,946 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:07:27,902 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,946 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:27,946 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,946 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,947 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,947 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,947 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,947 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,947 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,947 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,946 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,946 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/54eb36586184448298e3897ff2672c5b/handle.py", line 4, in <module>
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:07:27,947 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:07:27,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:07:27,948 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:07:27,946 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,948 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:07:27,949 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:07:27,949 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:07:27,900 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,948 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:07:27,950 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:07:27,948 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:07:27,950 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:07:27,950 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:27,950 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/54eb36586184448298e3897ff2672c5b/handle.py", line 4, in <module>
2022-03-15T00:07:27,948 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:07:27,950 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:07:27,951 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:07:27,951 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:27,951 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:27,951 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:27,951 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/54eb36586184448298e3897ff2672c5b/handle.py", line 4, in <module>
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:27,959 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:07:27,960 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:07:27,960 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:07:27,960 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:07:27,902 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,902 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,960 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,960 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,960 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,960 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,961 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:07:27,961 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:07:27,961 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:07:27,961 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:07:27,961 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:07:27,961 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:07:27,961 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:07:27,961 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:07:27,900 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,902 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,902 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,961 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,961 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,961 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,961 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,900 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,961 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,961 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,961 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,961 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,961 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:07:27,961 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:07:27,962 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:07:27,962 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:07:27,962 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:07:27,962 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:07:27,962 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:07:27,962 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:07:27,964 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:07:27,964 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:07:27,964 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:07:27,964 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:07:27,964 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:07:27,964 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:07:27,965 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:07:27,965 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:07:27,948 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,965 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,966 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:07:27,966 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:07:27,903 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,903 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,966 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,966 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,966 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:07:27,966 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:07:27,966 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:07:27,966 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:07:27,966 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:07:27,966 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:07:27,966 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:07:27,966 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:07:27,966 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,966 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,967 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:07:27,967 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:07:27,967 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:07:27,967 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:07:27,967 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:07:27,967 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:07:27,967 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:07:27,967 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:07:27,949 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:07:27,949 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:07:27,949 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:07:27,900 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:27,968 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:07:27,969 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,969 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:27,969 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,969 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:27,969 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:07:27,969 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:07:27,969 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,969 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:27,969 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:27,969 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:27,949 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:07:27,969 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:07:27,969 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:07:27,969 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:07:27,969 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:07:27,970 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:07:27,970 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:07:27,970 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:07:27,970 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:07:27,970 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:07:27,970 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:07:27,970 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:07:27,970 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:07:27,971 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:27,971 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,971 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:27,971 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:07:27,971 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:07:27,971 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:07:27,972 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:07:27,972 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:07:27,972 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:07:28,954 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:07:28,954 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:07:28,962 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:07:28,962 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:07:28,963 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:07:28,963 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:07:28,966 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:07:28,966 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:07:28,967 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:07:28,967 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:07:28,967 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:07:28,967 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:07:28,971 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:07:28,971 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:07:28,971 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:07:28,971 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:07:30,100 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,101 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41111
2022-03-15T00:07:30,101 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,101 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,101 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,101 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41109
2022-03-15T00:07:30,101 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,101 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,101 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,101 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41108
2022-03-15T00:07:30,101 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,101 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,101 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,101 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,101 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,101 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,102 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:07:30,101 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,101 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,102 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:07:30,102 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:07:30,102 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:07:30,102 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:07:30,102 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:07:30,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41106
2022-03-15T00:07:30,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,103 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,103 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,103 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:07:30,103 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:07:30,113 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,117 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41107
2022-03-15T00:07:30,117 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,117 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,117 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,117 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,117 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:07:30,117 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:07:30,118 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,121 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250121
2022-03-15T00:07:30,121 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250121
2022-03-15T00:07:30,128 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:07:30,128 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:07:30,128 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:07:30,128 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250128
2022-03-15T00:07:30,128 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250128
2022-03-15T00:07:30,129 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,129 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:07:30,129 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41105
2022-03-15T00:07:30,129 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,129 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:07:30,129 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,128 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41104
2022-03-15T00:07:30,129 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,129 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250129
2022-03-15T00:07:30,129 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250129
2022-03-15T00:07:30,130 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,129 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,130 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250130
2022-03-15T00:07:30,130 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250130
2022-03-15T00:07:30,130 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250130
2022-03-15T00:07:30,130 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250130
2022-03-15T00:07:30,130 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,130 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:07:30,130 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:07:30,130 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,130 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,131 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:07:30,131 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:07:30,137 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250137
2022-03-15T00:07:30,137 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:07:30,137 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250137
2022-03-15T00:07:30,140 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:07:30,140 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,144 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250144
2022-03-15T00:07:30,144 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250144
2022-03-15T00:07:30,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:30,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:30,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:30,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:30,155 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,155 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,157 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,164 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,165 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,177 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,177 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,177 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,189 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,157 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,226 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/54eb36586184448298e3897ff2672c5b/handle.py", line 4, in <module>
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:30,253 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:30,254 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:07:30,254 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:07:30,205 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:07:30,252 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,252 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,257 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,257 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,258 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,258 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,257 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41110
2022-03-15T00:07:30,260 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:07:30,260 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:07:30,189 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,261 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:07:30,261 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:07:30,262 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:07:30,262 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:07:30,263 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:07:30,263 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:07:30,262 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:07:30,262 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:07:30,263 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:07:30,263 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:07:30,177 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,264 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,264 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,264 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,264 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,265 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,265 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,265 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,265 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,263 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,263 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:07:30,265 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:07:30,265 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:07:30,185 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,265 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,265 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,265 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,265 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,266 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,266 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,266 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,266 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,266 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:07:30,177 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,266 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:07:30,266 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:07:30,266 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:07:30,267 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:07:30,267 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:07:30,267 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:07:30,267 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:07:30,177 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,267 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,267 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,267 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:07:30,267 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:07:30,266 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:07:30,267 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:07:30,267 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,267 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,268 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,165 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,267 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,267 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,271 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,271 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,271 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,271 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,268 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:07:30,163 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,268 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:07:30,271 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:07:30,271 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:07:30,271 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,271 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,271 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,271 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,271 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,271 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,271 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,271 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,273 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:30,273 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:30,164 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,163 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,273 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:07:30,273 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:07:30,273 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:07:30,273 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:07:30,273 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:07:30,273 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:07:30,273 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:07:30,273 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:07:30,273 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:07:30,273 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:07:30,274 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:07:30,274 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:07:30,273 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:07:30,273 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:07:30,273 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:30,274 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:30,274 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:30,274 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:30,274 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:07:30,274 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:07:30,163 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,275 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:07:30,275 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:07:30,275 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:07:30,274 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,163 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,162 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,275 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:07:30,275 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:30,274 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:30,275 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:30,275 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:30,268 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,276 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,276 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,276 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,276 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,266 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:07:30,267 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:07:30,275 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:30,274 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,278 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:07:30,278 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:07:30,278 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,278 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:07:30,278 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:30,278 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:30,278 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,278 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:30,278 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:07:30,278 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:07:30,278 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:07:30,278 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:30,279 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:07:30,279 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:07:30,279 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:07:30,279 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:07:30,279 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:07:30,280 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250280
2022-03-15T00:07:30,280 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317250280
2022-03-15T00:07:30,281 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:07:30,284 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:07:30,286 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:07:30,286 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:07:30,286 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:07:30,286 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,286 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:07:30,286 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,286 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:07:30,287 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,287 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:07:30,287 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,287 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/54eb36586184448298e3897ff2672c5b/handle.py", line 4, in <module>
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:07:30,287 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:30,287 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:07:30,287 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:07:30,287 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:07:30,287 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:09:37,714 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:09:37,714 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:09:37,748 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:09:37,748 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:09:37,778 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000730987-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:09:37,778 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000730987-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:09:37,784 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000730987-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317250987,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:09:37,784 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000730987-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317250987,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:09:37,787 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000730987-shutdown.cfg
2022-03-15T00:09:37,787 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000730987-shutdown.cfg
2022-03-15T00:09:37,787 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000730987-shutdown.cfg validated successfully
2022-03-15T00:09:37,787 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000730987-shutdown.cfg validated successfully
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:37,903 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:09:37,903 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:09:37,903 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:09:37,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:37,909 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:37,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:37,909 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:37,909 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:37,909 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:37,909 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:37,909 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:37,909 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:37,909 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:37,909 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:37,909 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:37,909 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:37,909 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:37,909 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:37,909 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:37,923 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:09:37,923 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:09:38,079 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:09:38,079 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:09:38,079 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:09:38,079 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:09:38,085 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:09:38,085 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:09:38,085 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:09:38,085 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:09:38,087 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:09:38,087 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:09:38,274 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:09:38,274 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:09:38,436 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:38,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.89685440063477|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:38,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.5348663330078|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:38,437 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:38,437 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2804.125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:38,437 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5117.109375|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:38,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.9|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317378
2022-03-15T00:09:52,571 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:09:52,571 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:09:52,601 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:09:52,601 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:09:52,626 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000938445-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:09:52,626 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000938445-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:09:52,630 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000938445-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317378445,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:09:52,630 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000938445-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317378445,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:09:52,633 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000938445-shutdown.cfg
2022-03-15T00:09:52,633 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000938445-shutdown.cfg
2022-03-15T00:09:52,633 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000938445-shutdown.cfg validated successfully
2022-03-15T00:09:52,633 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000938445-shutdown.cfg validated successfully
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:09:52,741 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:09:52,741 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:09:52,741 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:09:52,746 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:52,746 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:52,746 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:52,746 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:52,746 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:52,746 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:52,746 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:52,746 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:52,746 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:52,746 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:52,746 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:52,746 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:52,747 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:52,747 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:52,748 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:52,748 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:52,748 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:09:52,748 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:09:52,992 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:09:52,992 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:09:52,992 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:09:52,992 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:09:52,996 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:09:52,996 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:09:52,996 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:09:52,996 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:09:52,997 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:09:52,997 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:09:53,414 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:09:53,414 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:09:53,455 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:53,457 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.89709091186523|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:53,458 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.53462982177734|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:53,458 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:53,458 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2847.09375|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:53,458 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5256.578125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:53,459 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.6|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317393
2022-03-15T00:09:54,150 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,150 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,150 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,152 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41195
2022-03-15T00:09:54,152 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,152 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,150 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41194
2022-03-15T00:09:54,152 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41191
2022-03-15T00:09:54,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,152 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,152 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,152 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,152 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41197
2022-03-15T00:09:54,153 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,153 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,153 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,153 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,153 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,153 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,154 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,153 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,154 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,154 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41196
2022-03-15T00:09:54,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,155 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,155 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,154 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,155 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41193
2022-03-15T00:09:54,155 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,155 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,155 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,155 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,156 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:09:54,156 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:09:54,156 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:09:54,156 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:09:54,156 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:09:54,156 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:09:54,156 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:09:54,156 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:09:54,156 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:09:54,156 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:09:54,156 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:09:54,156 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:09:54,159 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,159 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41190
2022-03-15T00:09:54,159 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,159 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,160 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,160 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,160 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:09:54,160 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:09:54,160 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:54,160 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41192
2022-03-15T00:09:54,160 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:54,160 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,160 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:54,160 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:09:54,160 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:09:54,160 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:09:54,185 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:09:54,185 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:09:54,185 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:09:54,186 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:09:54,186 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:09:54,186 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:09:54,187 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:09:54,187 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:09:54,189 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,189 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317394189
2022-03-15T00:09:54,245 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,245 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,246 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,247 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,251 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,251 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,249 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,253 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:54,257 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,259 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,259 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,262 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,262 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,262 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,267 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,262 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,267 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,267 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,268 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,268 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:54,268 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,268 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:54,268 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:54,268 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,268 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:54,268 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:54,268 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:54,268 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:54,268 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:54,268 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,268 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,271 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,271 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,272 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,272 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,272 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,272 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,267 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,262 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,267 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,267 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,290 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,271 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,290 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,291 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,292 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,292 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,292 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,264 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,290 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,292 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,292 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:54,293 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:54,293 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:54,293 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:54,293 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:54,293 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:54,292 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,292 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,293 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:54,292 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,292 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,292 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,291 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,271 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,290 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:54,294 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,294 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,292 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,290 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,294 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,294 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:54,299 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:54,299 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:54,299 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:54,299 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:54,299 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:54,303 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,303 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:54,304 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:54,294 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,294 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,304 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,304 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,304 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,304 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,307 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:54,294 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,307 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:54,294 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,308 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:54,308 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,308 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,308 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,308 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,293 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,308 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/22ea3cef2f2c48bfa42e762e56f65b4b/handle.py", line 4, in <module>
2022-03-15T00:09:54,310 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:09:54,310 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:09:54,310 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:09:54,310 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:09:54,310 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:54,293 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:09:54,311 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:09:54,311 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:09:54,293 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,311 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,311 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,313 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,313 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,293 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,313 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,313 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,313 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,313 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,313 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:09:54,313 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:09:54,313 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:09:54,313 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:09:54,314 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:09:54,314 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:09:54,311 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:09:54,311 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:09:54,314 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:09:54,314 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:09:54,314 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:09:54,314 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:09:54,315 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:09:54,315 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:09:54,311 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:09:54,315 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:09:54,315 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,315 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,315 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:09:54,315 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,324 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:09:54,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:54,324 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:09:54,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:54,324 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:09:54,324 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:09:54,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:54,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:54,306 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:09:54,306 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:09:54,325 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:09:54,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:54,325 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:09:54,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:54,325 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:09:54,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:54,325 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:09:54,326 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/22ea3cef2f2c48bfa42e762e56f65b4b/handle.py", line 4, in <module>
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:09:54,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:54,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:54,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:09:54,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:09:54,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:09:54,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:09:54,327 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,294 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:54,294 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:54,328 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,328 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:54,328 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,328 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:54,328 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:54,328 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:09:54,328 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:09:54,328 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:09:54,328 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:09:54,328 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:09:54,328 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:09:54,328 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:09:54,328 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:09:54,293 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,330 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:09:54,329 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:54,330 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:09:54,330 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:09:54,293 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,330 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,330 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,330 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:54,330 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,330 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:09:54,330 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:09:54,330 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,294 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,294 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,330 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,330 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,330 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,330 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,332 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:09:54,332 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:09:54,332 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:09:54,332 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:09:54,332 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:09:54,332 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:09:54,333 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:09:54,333 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:09:54,333 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:09:54,333 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:09:54,295 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,295 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:54,333 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,333 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:54,333 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,333 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:54,334 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:09:54,334 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:54,334 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:09:54,334 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:09:54,334 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:09:54,334 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:09:54,335 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:09:54,335 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:09:54,306 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:09:54,335 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:54,335 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:09:54,306 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:09:54,335 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:09:54,335 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:54,335 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:54,334 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:09:54,334 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:09:54,336 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:09:54,335 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:54,336 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:09:54,335 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:54,336 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:09:54,336 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:09:54,336 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:09:54,336 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/22ea3cef2f2c48bfa42e762e56f65b4b/handle.py", line 4, in <module>
2022-03-15T00:09:54,336 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:09:54,336 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:09:54,336 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:09:54,336 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:09:54,336 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:09:54,336 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:09:54,336 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:09:55,319 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:55,319 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:55,320 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:55,320 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:55,326 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:55,326 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:55,326 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:55,326 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:55,331 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:55,331 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:55,333 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:55,333 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:55,335 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:55,335 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:55,338 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:55,338 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:56,414 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,415 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41204
2022-03-15T00:09:56,415 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,415 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,416 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,416 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,416 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:09:56,416 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:09:56,418 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,418 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41202
2022-03-15T00:09:56,418 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,418 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,418 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,418 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,418 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:09:56,418 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:09:56,427 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396427
2022-03-15T00:09:56,427 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396427
2022-03-15T00:09:56,439 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:09:56,440 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:09:56,441 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396441
2022-03-15T00:09:56,441 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396441
2022-03-15T00:09:56,461 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,461 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:56,462 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,462 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,464 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,464 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,464 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,464 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,464 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,464 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,464 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,464 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,464 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:09:56,464 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:09:56,464 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:09:56,464 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:09:56,464 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:09:56,464 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:09:56,464 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:09:56,464 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:09:56,470 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,470 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,472 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,472 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,472 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,472 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,472 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,472 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,472 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,472 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,476 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:09:56,476 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:09:56,476 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:09:56,476 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:09:56,476 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:09:56,476 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:09:56,476 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,476 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41205
2022-03-15T00:09:56,477 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,477 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,477 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:09:56,477 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:09:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,479 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:09:56,479 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:09:56,485 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:09:56,486 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:56,486 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:09:56,486 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:09:56,486 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,486 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:09:56,486 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:09:56,487 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,488 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41206
2022-03-15T00:09:56,488 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,488 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,488 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,488 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,488 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:09:56,488 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:09:56,489 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,489 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41201
2022-03-15T00:09:56,489 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,490 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,490 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,490 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,490 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:09:56,490 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:09:56,493 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396493
2022-03-15T00:09:56,493 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396493
2022-03-15T00:09:56,493 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396493
2022-03-15T00:09:56,493 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396493
2022-03-15T00:09:56,494 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:09:56,499 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396499
2022-03-15T00:09:56,499 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396499
2022-03-15T00:09:56,500 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,506 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,506 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:56,506 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,506 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:56,506 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:56,507 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:56,506 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:09:56,509 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:56,509 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,509 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:56,510 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:56,511 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,512 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41200
2022-03-15T00:09:56,512 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,512 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,513 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:56,513 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:56,513 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:56,513 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/22ea3cef2f2c48bfa42e762e56f65b4b/handle.py", line 4, in <module>
2022-03-15T00:09:56,513 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:09:56,513 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,513 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:09:56,513 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:09:56,514 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:09:56,514 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:09:56,514 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:09:56,515 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,515 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,515 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,515 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,515 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,515 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,515 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:56,515 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,515 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,515 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:56,516 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,516 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/22ea3cef2f2c48bfa42e762e56f65b4b/handle.py", line 4, in <module>
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:09:56,516 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:09:56,516 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:09:56,516 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:09:56,516 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:09:56,516 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:09:56,516 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:09:56,516 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:09:56,516 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:09:56,516 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:09:56,523 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,523 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,524 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,524 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,524 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,524 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,524 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,524 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,524 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,524 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,524 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:09:56,524 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:09:56,524 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:09:56,524 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:09:56,524 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:09:56,524 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:09:56,524 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:09:56,524 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:09:56,525 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:09:56,525 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,525 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,525 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,526 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,526 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,526 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41199
2022-03-15T00:09:56,526 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,526 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,526 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,526 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,526 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,526 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,526 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,526 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,526 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,526 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,526 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:09:56,526 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:09:56,526 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:09:56,526 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:09:56,526 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:09:56,526 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:09:56,526 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:09:56,526 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:09:56,526 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:09:56,526 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:09:56,527 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,527 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:09:56,527 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:09:56,528 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:09:56,529 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:09:56,529 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:09:56,530 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:09:56,530 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:09:56,530 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:09:56,532 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:09:56,533 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396533
2022-03-15T00:09:56,533 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396533
2022-03-15T00:09:56,537 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,538 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:56,539 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/22ea3cef2f2c48bfa42e762e56f65b4b/handle.py", line 4, in <module>
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:09:56,540 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:09:56,541 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,541 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:09:56,541 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:09:56,541 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:09:56,541 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:09:56,541 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,541 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,541 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,541 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,541 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,541 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,541 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,541 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,541 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,541 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,542 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:09:56,542 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:09:56,542 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:09:56,542 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:09:56,542 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:09:56,542 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:09:56,542 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:09:56,542 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:09:56,543 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:09:56,543 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:09:56,543 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:09:56,548 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:09:56,548 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41203
2022-03-15T00:09:56,548 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:09:56,548 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:09:56,548 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,548 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:09:56,548 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:09:56,548 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:09:56,550 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396550
2022-03-15T00:09:56,550 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396550
2022-03-15T00:09:56,553 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:09:56,555 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:56,556 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:56,556 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,556 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396556
2022-03-15T00:09:56,556 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317396556
2022-03-15T00:09:56,556 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,557 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:56,557 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:56,557 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:56,557 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,557 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,557 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:56,557 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,557 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,557 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,557 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,557 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,557 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,558 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:09:56,558 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:09:56,558 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:09:56,558 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:09:56,559 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:09:56,559 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:09:56,559 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:09:56,559 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:09:56,562 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:56,562 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:09:56,562 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:09:56,562 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:09:56,563 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:09:56,563 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:09:56,563 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:09:56,564 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,564 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:09:56,564 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:09:56,564 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:09:56,564 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,564 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:09:56,564 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,564 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:09:56,564 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:09:56,564 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:09:56,564 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:09:56,564 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:09:56,564 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:09:57,471 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:57,471 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:09:57,479 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:57,479 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:09:57,521 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:57,521 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:09:57,525 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:57,525 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:09:57,527 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:57,527 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:09:57,547 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:57,547 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:09:57,564 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:57,564 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:09:57,568 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:09:57,568 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:36,188 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:11:36,188 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:11:36,222 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:11:36,222 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:11:36,253 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000957963-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:11:36,253 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315000957963-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:11:36,258 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000957963-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317397963,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:11:36,258 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315000957963-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317397963,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:11:36,261 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000957963-shutdown.cfg
2022-03-15T00:11:36,261 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315000957963-shutdown.cfg
2022-03-15T00:11:36,261 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000957963-shutdown.cfg validated successfully
2022-03-15T00:11:36,261 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315000957963-shutdown.cfg validated successfully
2022-03-15T00:11:36,382 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:11:36,382 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:11:36,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:36,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:36,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:36,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:36,383 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:11:36,383 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:11:36,383 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:11:36,383 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:11:36,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:36,389 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:36,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:36,390 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:36,390 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:36,389 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:36,390 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:36,390 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:36,389 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:36,390 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:36,389 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:36,390 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:36,389 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:36,390 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:36,389 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:36,390 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:36,393 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:11:36,393 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:11:36,541 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:11:36,541 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:11:36,541 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:11:36,541 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:11:36,542 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:11:36,542 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:11:36,543 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:11:36,543 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:11:36,543 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:11:36,543 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:11:36,968 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:11:36,968 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:11:50,340 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:11:50,340 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:11:50,370 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:11:50,370 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:11:50,395 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001136993-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:11:50,395 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001136993-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:11:50,399 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001136993-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317496993,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:11:50,399 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001136993-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317496993,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:11:50,402 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001136993-shutdown.cfg
2022-03-15T00:11:50,402 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001136993-shutdown.cfg
2022-03-15T00:11:50,403 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001136993-shutdown.cfg validated successfully
2022-03-15T00:11:50,403 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001136993-shutdown.cfg validated successfully
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:11:50,511 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:11:50,511 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:11:50,511 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:11:50,517 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:50,517 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:50,517 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:50,517 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:50,517 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:50,518 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:50,517 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:50,518 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:50,519 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:50,519 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:50,520 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:50,520 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:50,525 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:50,525 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:50,528 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:50,528 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:50,529 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:11:50,529 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:11:50,623 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:11:50,623 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:11:50,623 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:11:50,623 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:11:50,624 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:11:50,624 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:11:50,625 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:11:50,625 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:11:50,626 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:11:50,626 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:11:51,261 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:11:51,261 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:11:51,302 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,302 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8957176208496|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,303 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.53600311279297|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,303 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,303 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2801.265625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,303 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5183.703125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,303 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.9|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317511
2022-03-15T00:11:51,769 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,770 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41295
2022-03-15T00:11:51,771 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,771 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,770 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,772 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,774 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,774 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41298
2022-03-15T00:11:51,774 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,774 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,776 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,776 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,776 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,778 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41299
2022-03-15T00:11:51,778 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,778 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,779 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,779 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:11:51,779 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:11:51,779 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,779 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:11:51,779 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:11:51,779 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:11:51,779 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:11:51,782 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,785 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41296
2022-03-15T00:11:51,785 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,786 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,786 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,786 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,786 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:11:51,786 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:11:51,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41294
2022-03-15T00:11:51,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,788 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,788 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,788 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:11:51,788 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:11:51,795 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,798 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41300
2022-03-15T00:11:51,798 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,798 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,798 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,798 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,799 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:11:51,799 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:11:51,799 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,800 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511800
2022-03-15T00:11:51,800 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511800
2022-03-15T00:11:51,803 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:11:51,804 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41297
2022-03-15T00:11:51,804 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,804 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,804 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,804 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,805 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:11:51,805 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:11:51,806 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511806
2022-03-15T00:11:51,806 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511806
2022-03-15T00:11:51,806 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:51,808 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511808
2022-03-15T00:11:51,808 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511808
2022-03-15T00:11:51,811 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511811
2022-03-15T00:11:51,811 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511811
2022-03-15T00:11:51,811 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:11:51,811 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:11:51,812 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511812
2022-03-15T00:11:51,812 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511812
2022-03-15T00:11:51,813 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511813
2022-03-15T00:11:51,813 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511813
2022-03-15T00:11:51,814 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41293
2022-03-15T00:11:51,813 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:11:51,813 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:11:51,813 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:11:51,813 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:11:51,814 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,814 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:51,814 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:11:51,814 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:11:51,814 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:51,814 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511814
2022-03-15T00:11:51,814 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:11:51,814 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511814
2022-03-15T00:11:51,818 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511818
2022-03-15T00:11:51,818 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317511818
2022-03-15T00:11:51,819 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:11:51,862 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,874 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,875 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,875 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,875 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,875 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,878 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,879 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,879 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,879 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:51,879 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:51,879 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:51,879 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:51,878 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,879 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:51,880 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:51,880 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:51,880 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:51,879 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,891 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,892 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,879 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:51,906 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:51,905 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,892 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,891 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,889 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,910 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,910 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,910 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:51,910 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,910 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:51,889 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:51,911 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:51,911 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,911 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,919 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,919 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,911 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,911 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,920 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,920 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,920 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,920 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,927 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:11:51,927 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:11:51,927 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:11:51,927 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:11:51,927 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:11:51,927 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:11:51,927 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:11:51,927 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:11:51,911 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,911 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,929 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,929 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,929 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,929 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,929 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,929 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,930 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:11:51,930 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:11:51,930 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:11:51,930 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:11:51,930 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:11:51,930 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:11:51,930 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:11:51,930 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:11:51,931 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:11:51,931 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:11:51,931 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:11:51,931 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:11:51,931 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:11:51,931 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:11:51,931 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:11:51,931 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:11:51,936 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,936 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,936 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,936 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,937 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,937 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,937 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,937 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,937 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,937 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,937 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,937 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,937 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,937 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,937 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:51,937 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,937 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,938 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:11:51,938 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:11:51,938 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:11:51,938 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:11:51,938 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:11:51,938 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:11:51,938 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:11:51,937 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:51,938 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:11:51,939 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:11:51,939 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:11:51,939 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:11:51,939 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:11:51,939 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:11:51,943 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:51,943 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:11:51,943 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/7bca381cd0d94c309941bab228a6f23c/handle.py", line 34, in initialize
2022-03-15T00:11:51,943 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     model = MatrixFactorization()
2022-03-15T00:11:51,943 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - NameError: name 'MatrixFactorization' is not defined
2022-03-15T00:11:51,943 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,943 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:11:51,943 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:11:51,947 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,947 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:51,947 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:11:51,947 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:11:51,947 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,947 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,947 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,947 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,947 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,948 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,948 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,948 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:11:51,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:11:51,948 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:11:51,948 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:11:51,948 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:11:51,948 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:11:51,948 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,948 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,948 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:11:51,948 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,948 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,948 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:11:51,949 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,949 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,949 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,949 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,949 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:11:51,949 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:11:51,949 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:11:51,949 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:11:51,949 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:11:51,949 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:11:51,949 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:11:51,949 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:51,949 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:51,950 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,950 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:11:51,950 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:51,949 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:11:51,950 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:11:51,950 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:11:51,950 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:11:51,950 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,950 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:51,951 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,950 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:11:51,951 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:51,951 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,951 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:51,951 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:11:51,951 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:11:51,952 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:11:51,952 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:11:51,953 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:11:51,953 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:11:51,953 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:11:51,953 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:11:51,953 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:11:51,953 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:11:51,954 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:51,954 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:11:51,954 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:11:52,936 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:52,936 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:52,938 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:52,938 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:52,938 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:52,938 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:52,940 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:52,940 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:52,940 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:52,940 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:52,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:52,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:52,951 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:52,951 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:52,954 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:52,954 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:54,044 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,045 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41305
2022-03-15T00:11:54,045 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,045 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,045 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,045 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,050 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:11:54,050 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:11:54,068 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514068
2022-03-15T00:11:54,068 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514068
2022-03-15T00:11:54,068 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:11:54,084 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,085 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41302
2022-03-15T00:11:54,085 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,085 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,085 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,085 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,085 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:11:54,085 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:11:54,094 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,094 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41304
2022-03-15T00:11:54,094 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,094 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,095 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,095 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,095 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:11:54,095 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:11:54,100 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,100 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,101 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,102 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:54,104 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514104
2022-03-15T00:11:54,104 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514104
2022-03-15T00:11:54,104 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:11:54,120 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,120 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,120 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,121 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41306
2022-03-15T00:11:54,121 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,121 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,121 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:11:54,122 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,122 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:54,122 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,122 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,122 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,122 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,122 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,122 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,122 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:11:54,122 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:11:54,123 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514123
2022-03-15T00:11:54,123 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514123
2022-03-15T00:11:54,122 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,131 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,122 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:11:54,131 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,131 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,123 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/7bca381cd0d94c309941bab228a6f23c/handle.py", line 34, in initialize
2022-03-15T00:11:54,132 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41303
2022-03-15T00:11:54,132 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     model = MatrixFactorization()
2022-03-15T00:11:54,132 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - NameError: name 'MatrixFactorization' is not defined
2022-03-15T00:11:54,132 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:11:54,132 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:11:54,133 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:11:54,133 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:11:54,133 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:11:54,133 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:11:54,133 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:11:54,133 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:11:54,132 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,133 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:11:54,134 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,134 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,134 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:11:54,134 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:11:54,133 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:11:54,134 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,134 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,134 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,134 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,134 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,135 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,135 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,134 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,135 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41309
2022-03-15T00:11:54,135 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,135 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,134 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,135 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,135 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,135 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,135 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,135 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,136 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,136 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,136 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,136 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:11:54,136 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:11:54,136 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,136 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:54,135 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,137 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,137 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,137 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,137 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,140 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:11:54,140 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,140 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41308
2022-03-15T00:11:54,140 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,140 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,140 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:11:54,140 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:11:54,140 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:11:54,140 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:11:54,140 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:11:54,140 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:11:54,140 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:11:54,140 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:11:54,140 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,140 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,140 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:11:54,140 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:11:54,141 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:54,141 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:11:54,141 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:11:54,142 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:11:54,142 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,143 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,144 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,144 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:54,144 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,144 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:54,145 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,145 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:11:54,145 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,145 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,145 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,145 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/7bca381cd0d94c309941bab228a6f23c/handle.py", line 34, in initialize
2022-03-15T00:11:54,145 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,145 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     model = MatrixFactorization()
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - NameError: name 'MatrixFactorization' is not defined
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:11:54,145 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:11:54,146 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:11:54,146 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:11:54,146 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:11:54,146 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:11:54,146 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:11:54,146 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:11:54,146 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:11:54,146 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:11:54,146 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514146
2022-03-15T00:11:54,146 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514146
2022-03-15T00:11:54,146 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514146
2022-03-15T00:11:54,146 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514146
2022-03-15T00:11:54,146 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514146
2022-03-15T00:11:54,146 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514146
2022-03-15T00:11:54,150 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:11:54,158 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,158 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,158 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,159 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,159 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,159 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,159 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,159 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,159 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,159 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,159 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,160 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,160 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,160 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,160 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,160 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:54,159 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,161 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,161 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,161 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,161 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,161 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,161 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,159 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,161 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,161 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,161 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,161 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,162 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,162 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,162 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,162 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,162 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:11:54,162 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:11:54,162 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:11:54,162 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:11:54,162 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:11:54,163 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:11:54,162 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:11:54,163 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:11:54,163 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:54,163 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41307
2022-03-15T00:11:54,163 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:54,163 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:54,163 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,163 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:54,163 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:11:54,163 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:11:54,163 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,163 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,164 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,164 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,164 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:11:54,164 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:11:54,164 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:11:54,164 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:11:54,164 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:11:54,164 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:11:54,164 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:11:54,164 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:11:54,165 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,165 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:54,165 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:11:54,165 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:11:54,165 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:11:54,165 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:11:54,166 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,166 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,167 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,167 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,167 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514167
2022-03-15T00:11:54,166 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,167 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514167
2022-03-15T00:11:54,167 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,167 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,167 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,170 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:11:54,170 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:11:54,170 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,170 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:11:54,170 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:11:54,170 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:11:54,171 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:11:54,171 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:11:54,171 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,171 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:11:54,171 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:11:54,175 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,176 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,176 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,176 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:54,176 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,176 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,176 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,176 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,177 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,177 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,177 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,177 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/7bca381cd0d94c309941bab228a6f23c/handle.py", line 34, in initialize
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     model = MatrixFactorization()
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - NameError: name 'MatrixFactorization' is not defined
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:11:54,177 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:11:54,177 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:11:54,177 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:11:54,177 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:11:54,177 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:11:54,202 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514202
2022-03-15T00:11:54,202 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317514202
2022-03-15T00:11:54,207 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:54,208 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:54,208 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:54,208 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:54,208 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:54,208 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:54,208 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:54,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:54,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:54,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:54,209 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,209 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:54,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,209 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:54,209 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:11:54,209 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:11:54,209 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:11:54,209 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:11:54,209 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:11:54,210 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:54,210 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:11:54,210 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:11:55,138 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:55,138 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:55,142 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:55,142 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:55,146 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:55,146 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:55,167 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:55,167 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:55,167 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:55,167 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:55,172 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:55,172 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:55,179 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:55,179 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:55,220 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:55,220 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:56,352 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,353 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41311
2022-03-15T00:11:56,353 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,353 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,353 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,353 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,353 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:11:56,353 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:11:56,364 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:11:56,364 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516364
2022-03-15T00:11:56,364 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516364
2022-03-15T00:11:56,376 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,376 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,376 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,376 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,379 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:56,379 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:56,379 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:56,379 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:56,379 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,379 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,379 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:56,381 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:56,381 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:56,381 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,381 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,381 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,381 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,381 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,381 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,382 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,382 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,382 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:11:56,382 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:11:56,382 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:11:56,382 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:11:56,382 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:11:56,382 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-03-15T00:11:56,382 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-03-15T00:11:56,382 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:11:56,392 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:56,392 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:11:56,392 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:11:56,407 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,407 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41313
2022-03-15T00:11:56,408 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,408 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,408 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,408 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,408 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:11:56,408 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:11:56,411 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,411 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,417 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41310
2022-03-15T00:11:56,417 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:11:56,417 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41314
2022-03-15T00:11:56,417 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,417 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,417 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516417
2022-03-15T00:11:56,417 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516417
2022-03-15T00:11:56,417 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,417 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,417 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,417 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,418 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:11:56,418 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:11:56,418 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:11:56,417 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,417 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,418 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:11:56,418 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,419 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,420 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,420 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,420 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:56,420 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:56,420 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:56,421 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:56,422 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:56,422 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:56,422 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:56,426 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:56,426 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:11:56,426 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/7bca381cd0d94c309941bab228a6f23c/handle.py", line 34, in initialize
2022-03-15T00:11:56,426 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     model = MatrixFactorization()
2022-03-15T00:11:56,426 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - NameError: name 'MatrixFactorization' is not defined
2022-03-15T00:11:56,434 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,434 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,434 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,434 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,435 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,435 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,435 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,435 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,435 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,435 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,435 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:11:56,435 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516435
2022-03-15T00:11:56,435 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516435
2022-03-15T00:11:56,436 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:11:56,436 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:11:56,435 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:11:56,436 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516436
2022-03-15T00:11:56,436 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516436
2022-03-15T00:11:56,436 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:11:56,436 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:11:56,436 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:11:56,436 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:11:56,436 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-03-15T00:11:56,436 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-03-15T00:11:56,436 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:11:56,436 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:11:56,437 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,437 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41315
2022-03-15T00:11:56,437 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,437 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,438 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,438 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,438 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,438 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:11:56,438 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:11:56,438 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:56,439 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:56,440 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,440 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,449 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,449 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,449 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,449 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,449 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,449 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,449 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,449 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,449 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,449 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,449 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:11:56,451 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,451 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,451 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,451 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,452 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,452 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,452 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,452 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,452 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:11:56,452 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:11:56,451 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:11:56,454 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516454
2022-03-15T00:11:56,454 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:11:56,451 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:11:56,454 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:11:56,454 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:11:56,454 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:11:56,454 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:11:56,454 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-03-15T00:11:56,454 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-03-15T00:11:56,454 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:11:56,454 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516454
2022-03-15T00:11:56,454 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:11:56,454 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:11:56,455 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-03-15T00:11:56,455 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-03-15T00:11:56,456 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,456 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,456 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41312
2022-03-15T00:11:56,456 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,456 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,456 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,456 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,456 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:11:56,456 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:11:56,457 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,457 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,457 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,457 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:56,457 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,457 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:56,457 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,457 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:56,458 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,458 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,458 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,458 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,458 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:56,458 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,458 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:56,458 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:56,458 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:11:56,458 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:11:56,458 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:11:56,458 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:11:56,458 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-03-15T00:11:56,462 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:56,462 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,463 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:11:56,463 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:11:56,463 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41317
2022-03-15T00:11:56,463 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,463 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,463 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:11:56,463 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,463 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,463 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:11:56,463 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:11:56,464 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:56,464 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:11:56,464 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:11:56,465 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,465 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:11:56,465 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:11:56,465 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:11:56,467 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41316
2022-03-15T00:11:56,467 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:11:56,467 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:11:56,467 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:11:56,467 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,467 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:11:56,468 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:11:56,468 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:11:56,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:11:56,476 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516476
2022-03-15T00:11:56,476 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516476
2022-03-15T00:11:56,476 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516476
2022-03-15T00:11:56,476 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516476
2022-03-15T00:11:56,476 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516476
2022-03-15T00:11:56,476 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317516476
2022-03-15T00:11:56,476 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,476 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,476 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:11:56,477 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,477 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,477 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:11:56,478 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:11:56,478 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:11:56,478 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:11:56,477 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,478 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,478 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,478 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,478 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:11:56,478 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,477 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:11:56,478 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,478 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,478 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,478 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:11:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,479 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,479 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,479 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,478 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,479 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:11:56,479 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,479 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,479 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,479 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,479 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,479 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,479 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:11:56,479 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,479 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:11:56,479 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,479 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:11:56,479 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:11:56,479 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:11:56,479 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:11:56,479 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:11:56,479 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-03-15T00:11:56,479 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-03-15T00:11:56,479 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:11:56,479 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-03-15T00:11:56,479 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:11:56,479 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:11:56,479 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-03-15T00:11:56,480 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:11:56,480 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-03-15T00:11:56,479 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:11:56,480 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:11:56,480 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:11:58,389 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:58,389 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:11:58,439 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:58,439 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:11:58,459 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:58,459 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:11:58,459 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:58,459 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:58,459 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:11:58,459 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:11:58,485 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:58,485 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:11:58,485 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:58,485 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:11:58,486 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:11:58,486 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:14:54,917 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:14:54,917 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:14:54,951 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:14:54,951 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:14:54,982 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001158788-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:14:54,982 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001158788-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:14:54,987 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001158788-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317518788,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:14:54,987 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001158788-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317518788,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:14:54,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001158788-shutdown.cfg
2022-03-15T00:14:54,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001158788-shutdown.cfg
2022-03-15T00:14:54,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001158788-shutdown.cfg validated successfully
2022-03-15T00:14:54,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001158788-shutdown.cfg validated successfully
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:14:55,106 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:14:55,106 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:14:55,106 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:14:55,112 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:14:55,112 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:14:55,112 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:14:55,112 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:14:55,112 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:14:55,112 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:14:55,112 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:14:55,112 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:14:55,112 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:14:55,112 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:14:55,112 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:14:55,112 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:14:55,112 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:14:55,112 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:14:55,112 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:14:55,114 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:14:55,114 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:14:55,112 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:14:55,234 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:14:55,234 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:14:55,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:14:55,234 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:14:55,236 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:14:55,236 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:14:55,236 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:14:55,236 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:14:55,237 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:14:55,237 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:14:55,552 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:14:55,552 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:14:55,651 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:55,652 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8996124267578|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:55,653 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.53210830688477|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:55,653 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:55,653 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2775.0625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:55,653 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5175.921875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:55,653 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.1|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317695
2022-03-15T00:14:56,559 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41400
2022-03-15T00:14:56,560 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41397
2022-03-15T00:14:56,560 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41394
2022-03-15T00:14:56,560 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:14:56,560 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41398
2022-03-15T00:14:56,560 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41401
2022-03-15T00:14:56,561 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,560 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,560 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41395
2022-03-15T00:14:56,561 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,561 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,561 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,561 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41399
2022-03-15T00:14:56,561 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,561 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,561 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,561 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,561 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,561 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,561 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,560 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41396
2022-03-15T00:14:56,561 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,561 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:14:56,561 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:14:56,561 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,561 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:14:56,563 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:14:56,563 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:14:56,563 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:14:56,563 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:14:56,563 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:14:56,563 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:14:56,563 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:14:56,563 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:14:56,563 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:14:56,563 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:14:56,563 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:14:56,563 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:14:56,563 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:14:56,563 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:14:56,563 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:14:56,563 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:14:56,590 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696590
2022-03-15T00:14:56,590 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696590
2022-03-15T00:14:56,591 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:14:56,591 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:14:56,591 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:14:56,591 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:14:56,591 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:14:56,591 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:14:56,591 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:14:56,591 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:14:56,592 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,591 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,592 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317696591
2022-03-15T00:14:56,626 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,627 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,634 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,635 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,637 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,639 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,639 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,639 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,640 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:14:56,647 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:14:56,648 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:14:56,648 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,648 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,649 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,649 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,650 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,650 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,651 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,651 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,663 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,665 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,664 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,664 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,664 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,665 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,664 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,664 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,640 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:14:56,640 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,750 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,740 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:14:56,750 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,753 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,664 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,665 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,753 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:14:56,753 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,753 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/bbcda422f7af4d9cae4fd24f0d867d9a/handle.py", line 34, in initialize
2022-03-15T00:14:56,753 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,753 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     model = MatrixFactorization()
2022-03-15T00:14:56,753 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,753 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - NameError: name 'MatrixFactorization' is not defined
2022-03-15T00:14:56,754 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,753 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,754 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:14:56,754 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,754 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,754 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,664 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,755 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,755 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,664 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,754 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:14:56,755 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,755 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:14:56,755 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:14:56,755 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,664 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:14:56,664 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,663 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,755 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,755 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,665 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:14:56,664 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,665 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,754 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,740 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,750 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,771 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,771 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,772 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,772 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:14:56,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,772 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:14:56,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:14:56,772 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:14:56,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:14:56,773 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:14:56,773 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:14:56,773 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:14:56,780 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:14:56,780 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,780 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:14:56,781 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:14:56,784 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,785 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,785 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,785 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:14:56,785 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,785 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,785 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:14:56,785 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:14:56,785 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,785 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:14:56,786 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:14:56,789 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,789 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:14:56,754 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,755 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,754 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,755 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,754 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,754 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,796 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,796 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,796 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,755 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,796 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,796 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,796 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,796 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,796 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,796 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,796 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,756 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,796 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,756 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,797 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,797 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,797 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,797 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,756 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,756 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,797 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,797 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,797 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,797 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,798 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:14:56,798 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:14:56,798 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:14:56,755 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,798 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:14:56,755 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,755 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,798 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,798 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,798 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,798 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:14:56,798 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:14:56,798 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:14:56,798 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:14:56,798 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:14:56,798 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:14:56,796 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,755 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,798 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,755 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:14:56,799 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,799 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,799 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,799 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,799 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:14:56,799 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:14:56,799 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:14:56,799 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:14:56,799 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:14:56,799 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:14:56,799 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:14:56,799 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:14:56,799 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:14:56,799 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:14:56,798 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:14:56,799 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:14:56,801 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,801 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,799 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:14:56,801 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:14:56,798 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:14:56,801 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:14:56,801 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:14:56,801 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:14:56,799 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:14:56,801 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:14:56,801 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:14:56,801 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:14:56,801 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:14:56,801 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:14:56,798 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:14:56,799 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:14:56,801 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:14:56,801 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:14:56,801 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:14:56,801 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:14:56,802 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:14:56,802 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:14:56,801 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:14:56,798 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:14:56,802 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:14:56,802 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:14:56,798 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:14:56,799 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:14:56,803 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:14:56,798 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:14:56,803 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:14:56,803 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:14:56,803 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:14:56,803 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:14:56,803 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:14:56,803 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:14:56,803 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:14:56,803 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:14:56,799 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:14:56,803 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:14:56,799 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:14:56,799 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:14:56,802 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,799 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:14:56,804 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:14:56,804 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:14:56,799 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:14:56,806 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:14:56,806 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:14:56,806 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:14:56,806 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:14:56,806 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:14:56,806 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:14:56,806 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:14:56,806 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:14:56,806 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:14:56,812 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:14:56,812 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:14:56,812 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:14:57,807 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:14:57,807 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:14:57,808 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:14:57,808 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:14:57,809 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:14:57,809 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:14:57,809 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:14:57,809 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:14:57,809 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:14:57,809 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:14:57,810 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:14:57,809 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:14:57,809 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:14:57,809 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:14:57,809 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:14:57,810 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:03,101 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:15:03,101 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:15:03,132 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:15:03,132 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:15:03,158 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001458528-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:15:03,158 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001458528-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:15:03,161 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001458528-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317698528,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:15:03,161 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001458528-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317698528,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:15:03,164 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001458528-shutdown.cfg
2022-03-15T00:15:03,164 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001458528-shutdown.cfg
2022-03-15T00:15:03,165 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001458528-shutdown.cfg validated successfully
2022-03-15T00:15:03,165 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001458528-shutdown.cfg validated successfully
2022-03-15T00:15:03,274 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:15:03,274 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:15:03,275 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:15:03,275 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:15:03,275 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:15:03,275 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:15:03,275 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:15:03,275 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:15:03,275 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:15:03,275 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:15:03,280 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:15:03,280 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:15:03,280 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:15:03,280 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:15:03,281 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:15:03,281 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:15:03,280 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:03,280 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:03,283 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:15:03,283 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:15:03,283 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:15:03,283 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:15:03,285 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:15:03,288 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:15:03,288 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:15:03,285 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:15:03,290 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:15:03,290 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:15:03,545 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:15:03,545 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:15:03,545 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:15:03,545 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:15:03,546 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:15:03,546 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:15:03,546 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:15:03,546 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:15:03,548 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:15:03,548 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:15:04,066 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:15:04,066 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:15:04,108 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,108 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.89923095703125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,109 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.53248977661133|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,109 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,109 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2780.46875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,110 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5042.890625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,110 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317704
2022-03-15T00:15:04,555 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,556 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41437
2022-03-15T00:15:04,556 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,556 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,557 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,557 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,557 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,557 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41442
2022-03-15T00:15:04,558 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,558 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,558 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,558 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,559 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,566 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:15:04,566 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:15:04,566 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:15:04,566 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,566 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:15:04,566 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41438
2022-03-15T00:15:04,567 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,567 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,567 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41439
2022-03-15T00:15:04,567 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,567 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,568 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,568 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,568 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,568 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:15:04,568 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,568 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:15:04,568 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:15:04,568 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:15:04,579 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:15:04,581 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704581
2022-03-15T00:15:04,581 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704581
2022-03-15T00:15:04,584 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,592 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41443
2022-03-15T00:15:04,592 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,592 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,592 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704592
2022-03-15T00:15:04,593 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,593 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,593 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:15:04,593 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:15:04,592 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704592
2022-03-15T00:15:04,596 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704596
2022-03-15T00:15:04,596 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704596
2022-03-15T00:15:04,596 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,600 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:15:04,596 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704596
2022-03-15T00:15:04,596 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:15:04,601 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704601
2022-03-15T00:15:04,596 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:15:04,596 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:15:04,603 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,601 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704601
2022-03-15T00:15:04,596 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704596
2022-03-15T00:15:04,616 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,616 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,616 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,616 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,616 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,616 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,616 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,624 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,624 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,626 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,626 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:04,628 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,628 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:04,629 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:04,629 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,631 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:04,631 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:04,633 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,633 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,636 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,637 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,636 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,640 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,641 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,641 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,637 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,641 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,641 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,651 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,651 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:04,652 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:04,653 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:04,653 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,653 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,661 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,643 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,640 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,668 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,668 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,668 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,668 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:04,668 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,668 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:04,668 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,668 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:04,665 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,651 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,640 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,668 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,640 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,675 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:15:04,675 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:15:04,675 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:15:04,675 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:15:04,675 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:15:04,675 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:15:04,677 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:15:04,677 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:15:04,661 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,677 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,677 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,677 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,677 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,678 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,678 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,679 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:15:04,679 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:15:04,679 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:15:04,679 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:15:04,679 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:15:04,679 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:15:04,679 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:15:04,679 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:15:04,643 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,686 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,686 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,686 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,675 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,675 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,686 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,686 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,686 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,687 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,687 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,688 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:15:04,688 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:15:04,688 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:15:04,688 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:15:04,689 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:15:04,688 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:15:04,688 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:15:04,689 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:15:04,689 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:15:04,689 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:15:04,689 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:15:04,689 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:15:04,689 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:15:04,689 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:15:04,689 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:15:04,689 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:15:04,690 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41444
2022-03-15T00:15:04,690 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,690 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,690 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,690 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,691 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:15:04,691 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:15:04,690 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,691 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41440
2022-03-15T00:15:04,691 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,691 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,691 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,691 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,691 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,691 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,691 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,691 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:15:04,691 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:15:04,691 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,691 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:04,692 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:04,692 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:04,692 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:04,692 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:04,695 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,695 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:15:04,695 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:15:04,696 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:04,696 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:15:04,696 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:15:04,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:04,696 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:04,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:15:04,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/967fa469ce74418f8fe732bb24b3f0a4/handle.py", line 40, in initialize
2022-03-15T00:15:04,696 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41441
2022-03-15T00:15:04,651 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:04,697 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:04,697 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:15:04,697 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:15:04,697 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,697 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:15:04,697 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.model = torch.load('/Users/changruimeng/Workspace/MovieRecommendation/model/model.pt')
2022-03-15T00:15:04,697 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:04,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 607, in load
2022-03-15T00:15:04,697 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:15:04,697 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:15:04,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2022-03-15T00:15:04,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 882, in _load
2022-03-15T00:15:04,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:15:04,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:15:04,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:15:04,698 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:15:04,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:15:04,698 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:15:04,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     result = unpickler.load()
2022-03-15T00:15:04,698 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:15:04,698 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:15:04,698 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:15:04,698 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:15:04,698 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:04,698 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:15:04,698 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:15:04,700 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704700
2022-03-15T00:15:04,700 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704700
2022-03-15T00:15:04,700 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:15:04,708 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704708
2022-03-15T00:15:04,708 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704708
2022-03-15T00:15:04,708 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,708 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:15:04,710 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:04,711 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:04,714 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:15:04,714 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,714 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,715 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,715 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704715
2022-03-15T00:15:04,715 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,718 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,718 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:04,715 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317704715
2022-03-15T00:15:04,719 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:15:04,719 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/967fa469ce74418f8fe732bb24b3f0a4/handle.py", line 40, in initialize
2022-03-15T00:15:04,720 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.model = torch.load('/Users/changruimeng/Workspace/MovieRecommendation/model/model.pt')
2022-03-15T00:15:04,720 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,720 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,720 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 607, in load
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 882, in _load
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     result = unpickler.load()
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 875, in find_class
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return super().find_class(mod_name, name)
2022-03-15T00:15:04,720 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:15:04,720 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:15:04,720 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:15:04,720 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:15:04,720 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:15:04,725 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,725 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,725 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,722 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,720 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:15:04,722 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,725 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,725 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,725 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,725 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,725 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:04,725 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,725 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,725 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,725 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:15:04,726 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:15:04,726 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:15:04,726 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:15:04,726 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:15:04,726 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - AttributeError: Can't get attribute 'MatrixFactorization' on <module '__main__' from '/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py'>
2022-03-15T00:15:04,726 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:15:04,726 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:15:04,726 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:15:04,727 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:04,728 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:04,728 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:04,728 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,728 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:04,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:04,728 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,728 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:04,728 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,728 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:04,728 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,728 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:04,729 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:15:04,729 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:15:04,729 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:15:04,729 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:15:04,729 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:15:04,729 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:15:04,730 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:15:04,730 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:15:04,730 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:04,730 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:15:04,730 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:15:05,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:15:05,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:15:05,685 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:15:05,685 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:15:05,691 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:15:05,691 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:15:05,691 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:15:05,691 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:15:05,699 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:15:05,699 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:15:05,725 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:15:05,725 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:15:05,727 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:05,727 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:05,732 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:15:05,732 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:15:06,776 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,776 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41452
2022-03-15T00:15:06,777 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,777 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,777 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,777 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,778 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:15:06,778 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:15:06,791 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:15:06,791 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706791
2022-03-15T00:15:06,791 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706791
2022-03-15T00:15:06,817 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,818 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41453
2022-03-15T00:15:06,818 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,818 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,818 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,818 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,818 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:15:06,818 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:15:06,817 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,818 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41455
2022-03-15T00:15:06,819 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,819 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,819 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,819 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,819 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:15:06,819 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:15:06,824 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,829 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41450
2022-03-15T00:15:06,829 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,829 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,829 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,829 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,829 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,830 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:15:06,830 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:15:06,829 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:15:06,830 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,831 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,831 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:06,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:06,838 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,838 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,838 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,838 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,838 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,838 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,838 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,838 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,838 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,838 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,839 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:15:06,839 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:15:06,839 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:15:06,839 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:15:06,839 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:15:06,839 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:15:06,846 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:15:06,846 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:15:06,847 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:15:06,848 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41449
2022-03-15T00:15:06,848 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,849 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,849 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,849 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:06,849 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:15:06,849 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:15:06,849 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:15:06,849 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,849 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:15:06,850 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706850
2022-03-15T00:15:06,850 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706850
2022-03-15T00:15:06,850 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706850
2022-03-15T00:15:06,850 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706850
2022-03-15T00:15:06,854 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:15:06,856 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706856
2022-03-15T00:15:06,856 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706856
2022-03-15T00:15:06,856 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,856 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41451
2022-03-15T00:15:06,856 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,856 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,857 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,857 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,857 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:15:06,857 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:15:06,858 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,859 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:15:06,862 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41454
2022-03-15T00:15:06,862 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:15:06,862 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,862 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,862 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41448
2022-03-15T00:15:06,862 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:15:06,863 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:15:06,863 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706863
2022-03-15T00:15:06,863 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706863
2022-03-15T00:15:06,863 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,863 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,863 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:15:06,863 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:15:06,863 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,863 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:15:06,863 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:15:06,863 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:15:06,863 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,872 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,872 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,872 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:06,872 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:15:06,872 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:06,872 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,872 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:15:06,872 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:06,874 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,874 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:06,874 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:06,874 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:06,874 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:06,874 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:06,875 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,875 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,875 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,875 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:06,878 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:15:06,879 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,879 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,879 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,879 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,875 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706875
2022-03-15T00:15:06,878 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:06,880 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:06,880 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:06,880 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:06,880 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:06,880 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:06,880 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:06,875 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706875
2022-03-15T00:15:06,875 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,883 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,879 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,883 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,885 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706885
2022-03-15T00:15:06,875 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706875
2022-03-15T00:15:06,875 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706875
2022-03-15T00:15:06,885 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317706885
2022-03-15T00:15:06,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:06,884 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:06,883 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,882 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,893 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:15:06,893 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/967fa469ce74418f8fe732bb24b3f0a4/handle.py", line 40, in initialize
2022-03-15T00:15:06,893 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.model = torch.load('/Users/changruimeng/Workspace/MovieRecommendation/model/model.pt')
2022-03-15T00:15:06,893 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 607, in load
2022-03-15T00:15:06,896 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2022-03-15T00:15:06,896 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 882, in _load
2022-03-15T00:15:06,897 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     result = unpickler.load()
2022-03-15T00:15:06,897 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 875, in find_class
2022-03-15T00:15:06,897 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return super().find_class(mod_name, name)
2022-03-15T00:15:06,883 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,899 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,899 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,899 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,899 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,899 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,899 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,899 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,899 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,900 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:15:06,900 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:15:06,900 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:15:06,900 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:15:06,900 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:15:06,900 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:15:06,900 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:15:06,900 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:15:06,883 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,908 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,908 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:06,908 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,908 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:15:06,908 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:15:06,908 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,875 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,909 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,909 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,909 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,879 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,911 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,911 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,911 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,911 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,911 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,911 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,911 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,911 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,911 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,908 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:06,911 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,913 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,913 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,913 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:06,913 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:15:06,913 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:15:06,914 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:15:06,914 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:15:06,914 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:15:06,914 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:15:06,914 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:15:06,914 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:15:06,914 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:15:06,914 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:15:06,914 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:15:06,914 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:15:06,915 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:15:06,915 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:15:06,915 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:15:06,915 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:15:06,915 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:15:06,914 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:06,915 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:15:06,915 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:15:06,915 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,915 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:15:06,915 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:15:06,915 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:15:06,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:15:06,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:06,925 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:06,929 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,929 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,930 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:15:06,930 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:15:06,930 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:15:06,930 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,930 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,930 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,930 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,930 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,930 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,930 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,930 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,933 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:15:06,933 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:15:06,933 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:15:06,933 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:15:06,933 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:15:06,933 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:15:06,934 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:15:06,934 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:15:06,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - AttributeError: Can't get attribute 'MatrixFactorization' on <module '__main__' from '/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py'>
2022-03-15T00:15:06,935 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:15:06,935 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:15:06,935 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,936 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:15:06,936 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:15:06,936 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:15:06,938 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,938 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,938 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,939 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,939 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,938 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:15:06,939 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,939 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,940 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,940 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,940 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,940 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,940 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,940 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:15:06,940 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,940 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/967fa469ce74418f8fe732bb24b3f0a4/handle.py", line 40, in initialize
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.model = torch.load('/Users/changruimeng/Workspace/MovieRecommendation/model/model.pt')
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 607, in load
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 882, in _load
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     result = unpickler.load()
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/serialization.py", line 875, in find_class
2022-03-15T00:15:06,940 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return super().find_class(mod_name, name)
2022-03-15T00:15:06,940 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,940 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:15:06,941 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,941 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:15:06,942 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:15:06,942 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:15:06,942 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:15:06,942 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:15:06,942 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:15:06,942 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:15:06,942 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:15:06,942 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:15:06,943 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:15:06,943 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:15:06,943 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:15:06,943 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:15:06,943 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:15:06,943 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:15:06,943 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:15:06,943 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:15:06,943 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:15:06,944 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:15:06,944 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:15:06,944 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - AttributeError: Can't get attribute 'MatrixFactorization' on <module '__main__' from '/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py'>
2022-03-15T00:15:06,944 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:15:06,944 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:15:07,852 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:15:07,852 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:15:07,903 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:15:07,903 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:15:07,914 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:15:07,914 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:15:07,914 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:15:07,914 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:15:07,915 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:15:07,915 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:15:07,938 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:15:07,938 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:15:07,944 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:07,944 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:15:07,944 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:15:07,944 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:17:31,215 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:17:31,215 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:17:31,252 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:17:31,252 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:17:31,284 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001508848-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:17:31,284 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001508848-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:17:31,289 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001508848-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317708848,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:17:31,289 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001508848-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317708848,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:17:31,292 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001508848-shutdown.cfg
2022-03-15T00:17:31,292 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001508848-shutdown.cfg
2022-03-15T00:17:31,292 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001508848-shutdown.cfg validated successfully
2022-03-15T00:17:31,292 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001508848-shutdown.cfg validated successfully
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:17:31,407 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:17:31,407 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:17:31,407 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:17:31,413 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:17:31,413 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:17:31,413 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:17:31,413 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:17:31,413 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:17:31,413 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:17:31,413 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:17:31,414 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:17:31,413 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:17:31,414 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:17:31,414 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:17:31,414 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:17:31,414 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:17:31,413 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:17:31,413 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:17:31,414 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:17:31,417 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:17:31,417 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:17:31,558 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:17:31,558 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:17:31,559 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:17:31,559 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:17:31,565 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:17:31,565 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:17:31,565 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:17:31,565 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:17:31,567 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:17:31,567 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:17:31,797 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:17:31,797 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:17:31,935 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:31,936 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.89824295043945|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:31,936 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.53347778320312|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:31,936 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:31,936 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2771.640625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:31,937 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5064.453125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:31,937 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.1|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317851
2022-03-15T00:17:32,902 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,902 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,902 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,903 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41549
2022-03-15T00:17:32,902 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,902 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,903 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41554
2022-03-15T00:17:32,902 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,902 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,903 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41555
2022-03-15T00:17:32,903 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,903 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41550
2022-03-15T00:17:32,904 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41552
2022-03-15T00:17:32,902 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:17:32,904 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,903 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41551
2022-03-15T00:17:32,903 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41548
2022-03-15T00:17:32,904 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,903 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,904 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,904 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,904 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,904 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,904 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,904 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,904 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,904 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,904 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,904 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,904 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41553
2022-03-15T00:17:32,905 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,904 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,905 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,905 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:17:32,905 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:17:32,905 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,905 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:17:32,906 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:17:32,906 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:17:32,906 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:17:32,906 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:17:32,906 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:17:32,906 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:17:32,906 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:17:32,906 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:17:32,906 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:17:32,906 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:17:32,906 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:17:32,906 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:17:32,906 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:17:32,906 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:17:32,906 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:17:32,906 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:17:32,947 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:17:32,948 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:17:32,948 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:17:32,949 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:17:32,949 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:17:32,949 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:17:32,950 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:17:32,950 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:17:32,951 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,951 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317852951
2022-03-15T00:17:32,997 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:32,997 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:32,998 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:32,997 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:32,997 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:32,999 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:33,004 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:33,007 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:17:33,010 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,010 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:17:33,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:17:33,011 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,018 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,018 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,018 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,018 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,018 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,018 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,018 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,018 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,019 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,019 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,019 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,022 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,022 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,017 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:17:33,024 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,024 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:17:33,025 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:17:33,025 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:17:33,025 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:17:33,019 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,019 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,020 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,020 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,026 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,026 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,026 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,026 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,026 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,026 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,026 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,026 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,026 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:17:33,022 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,026 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:17:33,026 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:17:33,026 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:17:33,026 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:17:33,022 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,026 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:17:33,026 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,026 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:17:33,024 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,018 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,026 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:17:33,018 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,026 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:17:33,019 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,026 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:17:33,026 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:17:33,024 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,018 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,027 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,025 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/3947588a6dc542589489a0de13ce651d/handle.py", line 4, in <module>
2022-03-15T00:17:33,022 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,022 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,027 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,027 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,027 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,027 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,027 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:17:33,026 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,027 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,027 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:17:33,027 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:17:33,027 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:17:33,019 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,027 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:17:33,027 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,027 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:17:33,027 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:17:33,027 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:17:33,027 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:17:33,027 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:17:33,028 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:17:33,027 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:17:33,028 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:17:33,028 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:17:33,028 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:17:33,028 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:17:33,018 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:17:33,028 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,028 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,028 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,028 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,029 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:17:33,029 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:17:33,029 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:17:33,029 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:17:33,027 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,038 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,038 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,038 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:17:33,038 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:17:33,038 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:17:33,038 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:17:33,038 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:17:33,038 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:17:33,026 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:17:33,027 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     from model.factor_model import MatrixFactorization
2022-03-15T00:17:33,039 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:17:33,026 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,039 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:17:33,026 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,040 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,040 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,039 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:17:33,039 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:17:33,040 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,040 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:17:33,040 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:17:33,039 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:17:33,039 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:17:33,041 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:17:33,041 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:17:33,042 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:17:33,042 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:17:33,039 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:17:33,038 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:17:33,038 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:17:33,027 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,043 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,043 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:17:33,043 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,043 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:17:33,041 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:17:33,043 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:17:33,041 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:17:33,043 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:17:33,043 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:17:33,044 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:17:33,044 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:17:33,044 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:17:33,044 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:17:33,044 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:17:33,044 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:17:33,041 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:17:33,041 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:17:33,044 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:17:33,044 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:17:33,039 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:17:33,044 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:17:33,043 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:17:33,044 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:17:33,044 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:17:33,044 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:17:33,047 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:17:33,047 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:17:33,047 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,049 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,049 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,049 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:17:33,049 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:17:33,050 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:17:33,050 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:17:33,056 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:17:33,056 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:17:33,056 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:17:34,031 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:17:34,031 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:17:34,032 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:17:34,032 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:17:34,039 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:17:34,039 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:17:34,040 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:17:34,040 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:17:34,043 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:17:34,043 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:17:34,044 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:17:34,044 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:17:34,045 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:17:34,045 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:17:34,045 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:17:34,045 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:19:25,620 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:19:25,620 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:19:25,655 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:19:25,655 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:19:25,686 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001734565-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:19:25,686 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001734565-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:19:25,691 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001734565-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317854565,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:19:25,691 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001734565-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317854565,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:19:25,694 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001734565-shutdown.cfg
2022-03-15T00:19:25,694 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001734565-shutdown.cfg
2022-03-15T00:19:25,695 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001734565-shutdown.cfg validated successfully
2022-03-15T00:19:25,695 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001734565-shutdown.cfg validated successfully
2022-03-15T00:19:25,811 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:19:25,811 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:19:25,811 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:25,811 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:25,812 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:25,812 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:25,812 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:19:25,812 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:19:25,812 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:19:25,812 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:19:25,818 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:19:25,818 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:19:25,818 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:19:25,818 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:19:25,818 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:19:25,818 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:19:25,818 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:19:25,818 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:19:25,818 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:19:25,818 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:19:25,818 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:19:25,818 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:19:25,818 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:19:25,818 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:19:25,821 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:19:25,821 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:19:25,823 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:19:25,823 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:19:25,932 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:19:25,932 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:19:25,932 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:19:25,932 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:19:25,933 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:19:25,933 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:19:25,933 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:19:25,933 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:19:25,934 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:19:25,934 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:19:26,381 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:19:26,381 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:19:26,437 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:26,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8974151611328|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:26,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.53430557250977|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:26,438 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:26,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2819.28125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:26,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5108.5|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:26,438 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.8|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317966
2022-03-15T00:19:29,734 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:19:29,734 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:19:29,764 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:19:29,764 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:19:29,789 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001926634-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:19:29,789 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001926634-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:19:29,792 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001926634-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317966634,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:19:29,792 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001926634-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317966634,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:19:29,795 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001926634-shutdown.cfg
2022-03-15T00:19:29,795 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001926634-shutdown.cfg
2022-03-15T00:19:29,796 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001926634-shutdown.cfg validated successfully
2022-03-15T00:19:29,796 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001926634-shutdown.cfg validated successfully
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:19:29,904 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:19:29,904 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:19:29,904 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:19:29,909 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:19:29,909 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:19:29,910 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:19:29,909 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:19:29,910 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:19:29,909 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:19:29,909 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:19:29,910 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:19:29,909 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:19:29,910 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:19:29,912 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:19:29,912 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:19:29,912 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:19:29,912 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:19:29,912 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:19:29,912 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:19:29,913 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:19:29,913 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:19:30,083 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:19:30,083 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:19:30,084 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:19:30,084 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:19:30,085 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:19:30,085 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:19:30,085 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:19:30,085 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:19:30,086 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:19:30,086 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:19:30,677 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:19:30,677 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:19:30,771 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:30,772 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.89739608764648|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:30,773 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.5343246459961|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:30,773 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:30,773 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2746.0625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:30,773 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5097.234375|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:30,773 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.2|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647317970
2022-03-15T00:19:31,212 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,214 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41705
2022-03-15T00:19:31,214 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,214 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,214 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,214 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41703
2022-03-15T00:19:31,215 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,215 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,216 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,216 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,217 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,217 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,223 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:19:31,223 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:19:31,223 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:19:31,223 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:19:31,233 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,234 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41707
2022-03-15T00:19:31,234 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,234 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,235 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,234 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,235 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:19:31,235 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:19:31,248 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:19:31,251 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971251
2022-03-15T00:19:31,251 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971251
2022-03-15T00:19:31,255 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,256 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41702
2022-03-15T00:19:31,255 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,256 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,256 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,256 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,256 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,256 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:19:31,256 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:19:31,259 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,260 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41706
2022-03-15T00:19:31,260 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,260 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,260 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:19:31,261 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:19:31,260 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41704
2022-03-15T00:19:31,261 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971261
2022-03-15T00:19:31,261 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,261 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971261
2022-03-15T00:19:31,261 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,261 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,261 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971261
2022-03-15T00:19:31,261 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971261
2022-03-15T00:19:31,261 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,262 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:19:31,262 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:19:31,261 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,263 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:19:31,263 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:19:31,261 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,265 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,266 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971266
2022-03-15T00:19:31,265 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,265 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:19:31,266 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41701
2022-03-15T00:19:31,266 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,266 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971266
2022-03-15T00:19:31,266 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,267 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:19:31,266 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,267 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:19:31,281 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:19:31,282 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971282
2022-03-15T00:19:31,282 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971282
2022-03-15T00:19:31,282 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,281 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:19:31,282 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971282
2022-03-15T00:19:31,282 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971282
2022-03-15T00:19:31,281 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:19:31,283 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:19:31,284 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:19:31,284 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:19:31,285 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:19:31,286 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,286 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,288 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,288 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,288 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,288 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,292 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,292 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,302 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,302 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,302 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,305 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,305 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,305 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:19:31,306 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:19:31,306 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:19:31,306 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:19:31,306 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:19:31,307 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:19:31,307 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:19:31,307 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:19:31,307 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:19:31,307 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:19:31,302 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,310 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,310 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,310 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,310 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,310 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,288 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,288 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,314 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,314 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,314 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,314 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,315 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971315
2022-03-15T00:19:31,315 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971315
2022-03-15T00:19:31,318 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:19:31,318 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:19:31,319 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:19:31,319 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:19:31,319 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:19:31,319 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:19:31,321 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:19:31,321 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:19:31,322 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:19:31,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:19:31,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:19:31,324 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:19:31,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:19:31,325 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:19:31,326 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:19:31,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:19:31,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:19:31,327 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:19:31,292 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,292 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,331 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,331 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,331 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,331 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,333 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:19:31,333 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:19:31,334 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:19:31,334 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:19:31,334 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:19:31,334 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:19:31,334 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:19:31,334 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:19:31,312 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,312 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,336 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,336 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,338 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,338 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,338 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,338 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,341 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:19:31,341 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:19:31,341 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:19:31,341 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:19:31,341 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:19:31,341 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:19:31,341 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:19:31,341 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:19:31,312 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,312 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,343 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,343 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,344 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,344 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,345 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,345 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,346 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:19:31,346 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:19:31,346 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:19:31,346 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:19:31,346 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:19:31,346 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:19:31,346 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:19:31,346 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:19:31,361 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,310 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,361 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,361 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,361 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,361 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,361 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,361 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,362 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,362 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:19:31,362 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:19:31,363 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:19:31,362 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:19:31,312 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,363 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:19:31,362 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:19:31,363 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:19:31,364 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:19:31,364 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:19:31,364 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:19:31,363 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:19:31,312 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,364 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:19:31,364 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:19:31,364 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:19:31,364 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,364 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:19:31,364 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,364 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,364 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,364 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,364 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,365 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:19:31,365 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:19:31,365 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:19:31,365 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:19:31,365 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:19:31,365 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:19:31,365 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:19:31,365 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:19:31,365 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,366 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:19:31,365 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:19:31,365 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,366 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:19:31,367 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,367 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,368 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:19:31,368 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,368 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:19:31,368 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,368 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:19:31,368 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,368 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,368 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:19:31,368 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,368 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,368 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,368 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:19:31,368 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:19:31,368 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:19:31,368 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,368 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:19:31,368 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:19:31,369 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:19:31,369 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:19:31,369 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,369 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:19:31,369 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:19:31,369 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:19:31,369 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41708
2022-03-15T00:19:31,369 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:19:31,369 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:19:31,370 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,370 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,370 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:19:31,370 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:19:31,370 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:19:31,370 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:19:31,370 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:19:31,379 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:19:31,380 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971380
2022-03-15T00:19:31,380 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647317971380
2022-03-15T00:19:31,387 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:19:31,388 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:19:31,388 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:19:31,388 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:19:31,388 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:19:31,388 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:19:31,388 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:19:31,388 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:19:31,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:19:31,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:19:31,389 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,389 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:19:31,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:19:31,389 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:19:31,389 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:19:31,389 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:19:31,389 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:19:31,390 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:19:31,389 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/e7d852875ce34e51a6f4fb456513cdaa/handle.py", line 4, in <module>
2022-03-15T00:19:31,390 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:19:31,390 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:19:31,390 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:19:32,329 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:19:32,329 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:19:32,336 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:19:32,336 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:19:32,343 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:19:32,343 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:19:32,347 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:19:32,347 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:19:32,369 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:19:32,369 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:19:32,369 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:19:32,369 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:19:32,370 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:19:32,370 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:19:32,391 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:19:32,391 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:25:47,330 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:25:47,330 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:25:47,365 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:25:47,365 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:25:47,398 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001933145-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:25:47,398 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315001933145-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:25:47,404 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001933145-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317973145,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:25:47,404 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315001933145-shutdown.cfg",
  "modelCount": 1,
  "created": 1647317973145,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:25:47,407 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001933145-shutdown.cfg
2022-03-15T00:25:47,407 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315001933145-shutdown.cfg
2022-03-15T00:25:47,407 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001933145-shutdown.cfg validated successfully
2022-03-15T00:25:47,407 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315001933145-shutdown.cfg validated successfully
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:25:47,521 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:25:47,521 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:25:47,521 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:25:47,528 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:25:47,528 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:25:47,528 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:25:47,528 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:25:47,528 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:25:47,528 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:25:47,528 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:25:47,528 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:25:47,528 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:25:47,528 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:25:47,528 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:25:47,528 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:25:47,528 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:25:47,529 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:25:47,528 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:25:47,529 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:25:47,530 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:25:47,530 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:25:47,634 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:25:47,634 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:25:47,635 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:25:47,635 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:25:47,638 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:25:47,638 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:25:47,638 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:25:47,638 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:25:47,639 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:25:47,639 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:25:47,909 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:25:47,909 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:25:48,058 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,059 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.88398361206055|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,059 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.54773712158203|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,060 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,060 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2700.453125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,060 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5030.171875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,060 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.5|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318348
2022-03-15T00:25:48,928 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,928 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,928 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41816
2022-03-15T00:25:48,927 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,928 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41812
2022-03-15T00:25:48,928 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,928 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,928 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,928 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,928 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41817
2022-03-15T00:25:48,928 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,928 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41818
2022-03-15T00:25:48,928 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,929 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41814
2022-03-15T00:25:48,929 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,928 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41815
2022-03-15T00:25:48,929 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,928 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:25:48,929 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,929 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41811
2022-03-15T00:25:48,929 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,929 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,929 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,929 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,929 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41813
2022-03-15T00:25:48,929 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,929 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,930 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,930 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:25:48,929 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,930 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:25:48,930 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:25:48,931 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:25:48,931 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:25:48,931 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:25:48,931 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:25:48,931 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:25:48,931 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:25:48,931 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:25:48,931 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:25:48,931 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:25:48,931 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:25:48,931 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:25:48,931 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:25:48,931 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:25:48,931 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:25:48,931 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:25:48,931 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:25:48,947 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348947
2022-03-15T00:25:48,947 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348947
2022-03-15T00:25:48,950 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:25:48,950 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:25:48,950 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:25:48,950 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:25:48,950 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:25:48,950 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:25:48,950 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318348950
2022-03-15T00:25:48,950 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:25:48,950 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:25:48,986 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,986 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,991 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,991 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,992 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,997 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,997 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:48,997 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:25:49,000 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,000 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,000 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:25:49,000 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:25:49,000 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:25:49,000 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:25:49,001 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:25:49,001 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:25:49,001 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,001 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,001 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:25:49,001 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,001 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,002 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,002 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,002 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,002 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,001 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:25:49,002 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,002 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,003 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,004 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,004 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:25:49,005 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,005 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:25:49,005 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,005 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,005 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:25:49,007 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,003 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,034 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,034 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,034 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,034 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,037 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,037 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,037 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,037 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,038 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:25:49,038 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:25:49,038 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:25:49,038 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:25:49,038 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:25:49,038 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:25:49,039 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:25:49,039 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:25:49,002 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:25:49,044 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,044 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,044 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,044 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,044 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,044 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,044 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,044 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,045 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:25:49,045 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:25:49,045 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:25:49,045 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:25:49,045 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:25:49,045 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:25:49,045 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:25:49,045 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:25:49,053 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,054 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,054 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:25:49,054 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:25:49,054 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:25:49,054 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:25:49,054 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:25:49,055 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:25:49,055 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:25:49,055 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:25:49,055 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:25:49,004 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,004 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,066 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,066 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,067 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,067 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,067 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,067 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,068 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:25:49,068 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:25:49,068 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:25:49,068 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:25:49,068 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:25:49,068 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:25:49,068 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:25:49,068 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:25:49,077 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:25:49,077 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:25:49,077 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:25:49,082 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,082 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:25:49,082 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:25:49,082 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,082 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,083 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:25:49,083 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:25:49,083 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:25:49,083 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:25:49,083 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:25:49,083 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:25:49,084 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:25:49,084 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:25:49,084 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:25:49,004 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,004 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,085 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,085 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,086 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,086 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,086 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,086 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,088 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:25:49,088 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:25:49,088 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:25:49,088 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:25:49,088 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:25:49,088 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:25:49,088 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:25:49,088 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:25:49,095 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:25:49,096 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,096 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:25:49,097 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:25:49,003 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,003 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,099 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,099 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,099 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,099 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,099 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,099 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,099 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:25:49,099 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:25:49,099 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:25:49,100 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:25:49,100 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:25:49,100 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:25:49,100 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:25:49,100 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:25:49,100 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:25:49,100 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:25:49,100 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:25:49,100 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:25:49,100 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:25:49,100 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:25:49,005 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,005 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,103 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,103 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,103 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,103 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,104 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:25:49,104 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:25:49,104 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:25:49,104 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:25:49,104 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:25:49,104 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:25:49,104 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:25:49,104 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/84a18546d20643cbb2a89fce6f117614/handle.py", line 4, in <module>
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:25:49,104 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:25:49,105 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:25:49,105 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:25:49,105 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:25:49,006 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,006 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:25:49,114 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,114 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:25:49,114 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,114 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:25:49,114 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:25:49,114 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:25:49,114 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:25:49,114 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:25:49,114 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:25:49,114 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:25:49,115 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:25:49,115 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:25:49,116 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:25:49,116 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:25:49,116 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:25:49,116 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/84a18546d20643cbb2a89fce6f117614/handle.py", line 4, in <module>
2022-03-15T00:25:49,116 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     from factor_model import MatrixFactorization
2022-03-15T00:25:49,116 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'factor_model'
2022-03-15T00:25:49,116 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:25:49,117 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:25:49,117 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:25:49,117 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:25:49,117 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:25:49,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:25:49,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:36,866 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:26:36,866 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:26:36,898 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:26:36,898 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:26:36,926 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315002549120-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:26:36,926 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315002549120-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:26:36,930 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315002549120-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318349120,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:26:36,930 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315002549120-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318349120,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:26:36,933 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315002549120-shutdown.cfg
2022-03-15T00:26:36,933 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315002549120-shutdown.cfg
2022-03-15T00:26:36,933 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315002549120-shutdown.cfg validated successfully
2022-03-15T00:26:36,933 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315002549120-shutdown.cfg validated successfully
2022-03-15T00:26:37,040 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:26:37,040 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:26:37,040 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:37,040 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:37,040 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:37,040 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:37,040 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:26:37,040 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:26:37,041 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:26:37,041 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:26:37,045 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:26:37,045 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:26:37,046 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:26:37,046 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:26:37,046 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:26:37,046 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:26:37,045 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:26:37,045 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:26:37,045 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:26:37,046 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:26:37,046 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:26:37,046 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:26:37,046 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:26:37,046 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:26:37,046 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:26:37,045 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:26:37,045 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:26:37,045 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:26:37,165 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:26:37,165 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:26:37,165 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:26:37,165 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:26:37,166 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:26:37,166 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:26:37,166 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:26:37,166 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:26:37,167 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:26:37,167 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:26:37,609 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:26:37,609 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:26:37,648 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:37,648 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.88348007202148|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:37,648 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.5482406616211|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:37,648 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:37,648 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2805.671875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:37,649 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5128.015625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:37,649 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.9|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318397
2022-03-15T00:26:41,928 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:26:41,928 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:26:41,959 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:26:41,959 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:26:41,984 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315002638211-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:26:41,984 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315002638211-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:26:41,988 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315002638211-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318398211,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:26:41,988 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315002638211-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318398211,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:26:41,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315002638211-shutdown.cfg
2022-03-15T00:26:41,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315002638211-shutdown.cfg
2022-03-15T00:26:41,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315002638211-shutdown.cfg validated successfully
2022-03-15T00:26:41,991 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315002638211-shutdown.cfg validated successfully
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:26:42,099 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:26:42,099 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:26:42,099 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:26:42,104 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:26:42,104 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:26:42,104 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:26:42,104 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:26:42,104 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:26:42,105 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:26:42,105 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:26:42,104 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:26:42,104 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:26:42,105 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:26:42,104 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:26:42,105 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:26:42,105 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:26:42,105 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:26:42,105 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:26:42,105 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:26:42,104 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:26:42,104 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:26:42,339 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:26:42,339 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:26:42,340 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:26:42,340 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:26:42,367 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:26:42,367 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:26:42,367 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:26:42,367 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:26:42,368 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:26:42,368 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:26:42,779 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:26:42,779 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:26:42,824 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:42,827 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.88347625732422|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:42,828 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.54824447631836|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:42,828 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:42,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2810.171875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:42,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5161.625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:42,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.8|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318402
2022-03-15T00:26:43,310 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,318 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41909
2022-03-15T00:26:43,318 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,318 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,319 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,319 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,323 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:26:43,323 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:26:43,336 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,337 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41907
2022-03-15T00:26:43,337 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,337 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,338 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,338 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,339 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:26:43,339 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:26:43,342 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,344 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,347 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,348 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:26:43,349 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403349
2022-03-15T00:26:43,349 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403349
2022-03-15T00:26:43,355 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403355
2022-03-15T00:26:43,355 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41904
2022-03-15T00:26:43,355 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:26:43,355 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403355
2022-03-15T00:26:43,356 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,356 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,355 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41903
2022-03-15T00:26:43,356 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,356 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,356 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,356 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,356 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:26:43,356 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:26:43,355 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41906
2022-03-15T00:26:43,357 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,357 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,361 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403361
2022-03-15T00:26:43,357 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,361 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403361
2022-03-15T00:26:43,361 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:26:43,357 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,357 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,362 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,366 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:26:43,366 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:26:43,366 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:26:43,366 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:26:43,372 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,376 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41902
2022-03-15T00:26:43,376 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,376 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,376 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,377 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:26:43,376 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,377 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:26:43,380 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403380
2022-03-15T00:26:43,380 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,380 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403380
2022-03-15T00:26:43,380 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403380
2022-03-15T00:26:43,380 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403380
2022-03-15T00:26:43,383 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,384 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,386 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403386
2022-03-15T00:26:43,385 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,384 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,384 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:26:43,386 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,388 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,386 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,386 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:26:43,386 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403386
2022-03-15T00:26:43,394 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,388 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,400 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,400 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,401 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,401 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,405 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,406 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,406 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,406 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,407 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,400 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,408 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,409 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,406 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,409 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,409 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,406 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,410 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,401 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,411 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,411 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,411 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41905
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,411 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,411 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,401 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,411 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,411 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,412 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,412 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:26:43,411 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,412 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,401 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,410 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,411 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,412 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,410 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,412 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,409 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:43,407 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,410 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,412 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,412 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,412 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:26:43,411 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,423 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:26:43,425 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,426 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:43,414 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,412 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,413 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,412 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,413 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,414 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,436 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,434 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,436 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,436 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,436 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,437 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,437 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,430 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,437 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,437 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,437 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,436 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:43,437 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,437 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2022-03-15T00:26:43,437 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,437 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:43,437 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _get_class_entry_point
2022-03-15T00:26:43,438 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     raise ValueError("Expected only one class in custom service code or a function entry point {}".format(
2022-03-15T00:26:43,438 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,438 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - ValueError: Expected only one class in custom service code or a function entry point [<class 'handle.MatrixFactorization'>, <class 'handle.ModelHandler'>]
2022-03-15T00:26:43,438 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,437 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,412 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,438 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,439 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,439 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,439 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,439 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,413 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,437 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,440 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,440 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,413 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,440 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,440 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,440 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,440 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,440 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,440 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,412 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,440 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,440 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,440 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,440 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,440 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,437 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,437 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,446 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:26:43,440 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,446 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:26:43,440 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,446 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,442 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:43,446 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,446 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,446 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,442 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:43,446 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2022-03-15T00:26:43,446 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:26:43,441 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,449 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:26:43,449 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _get_class_entry_point
2022-03-15T00:26:43,450 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     raise ValueError("Expected only one class in custom service code or a function entry point {}".format(
2022-03-15T00:26:43,450 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - ValueError: Expected only one class in custom service code or a function entry point [<class 'handle.MatrixFactorization'>, <class 'handle.ModelHandler'>]
2022-03-15T00:26:43,450 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:26:43,450 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:26:43,442 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:26:43,451 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:26:43,451 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:26:43,442 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:26:43,451 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:26:43,451 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:26:43,453 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:26:43,453 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:26:43,441 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:26:43,441 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:26:43,453 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:26:43,453 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:26:43,436 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,440 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,441 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:26:43,441 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:26:43,454 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:26:43,454 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:26:43,454 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:26:43,454 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:26:43,446 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:26:43,446 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:26:43,455 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:26:43,443 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:43,455 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:26:43,446 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:26:43,455 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:26:43,455 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:26:43,455 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:26:43,455 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:26:43,457 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403457
2022-03-15T00:26:43,455 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:26:43,457 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403457
2022-03-15T00:26:43,458 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:26:43,458 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:26:43,458 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:26:43,458 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:26:43,458 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:26:43,458 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:26:43,455 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:26:43,455 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:26:43,455 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:26:43,466 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2022-03-15T00:26:43,468 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:26:43,468 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:43,468 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:26:43,468 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:26:43,468 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:26:43,468 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:43,468 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41908
2022-03-15T00:26:43,468 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:43,468 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:43,468 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,468 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:26:43,468 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:26:43,468 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:26:43,472 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403472
2022-03-15T00:26:43,472 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318403472
2022-03-15T00:26:43,473 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,472 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,474 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:43,474 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,474 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,475 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,475 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,475 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,475 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,476 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,476 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,476 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,476 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,476 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:26:43,476 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:26:43,476 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:26:43,476 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:26:43,476 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:26:43,476 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:26:43,476 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:26:43,476 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:26:43,479 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:43,479 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:26:43,479 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:26:43,479 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:43,481 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:43,481 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:43,481 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:43,481 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,481 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:43,481 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:43,482 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:43,482 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:43,482 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,482 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:43,482 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,482 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:43,482 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,482 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:43,482 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:26:43,482 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:26:43,482 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:26:43,483 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:26:43,483 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:26:43,483 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:26:43,483 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:43,483 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:26:43,483 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:26:43,483 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:26:44,457 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:26:44,457 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:26:44,457 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:26:44,457 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:26:44,457 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:26:44,457 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:26:44,457 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:26:44,457 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:26:44,457 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:26:44,457 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:26:44,459 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:26:44,459 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:26:44,481 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:26:44,481 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:26:44,487 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:26:44,487 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:26:45,544 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,545 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]41915
2022-03-15T00:26:45,545 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,545 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,547 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,547 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,547 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:26:45,547 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:26:45,560 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:26:45,561 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405561
2022-03-15T00:26:45,561 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405561
2022-03-15T00:26:45,585 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,585 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]41913
2022-03-15T00:26:45,586 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,586 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,595 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,595 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,595 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:26:45,595 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:26:45,597 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,597 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]41912
2022-03-15T00:26:45,597 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,597 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,597 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,597 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,597 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:26:45,597 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:26:45,608 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405607
2022-03-15T00:26:45,608 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405607
2022-03-15T00:26:45,608 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,608 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:26:45,617 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,617 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,617 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,617 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,617 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,617 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,617 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,618 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,618 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,618 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,618 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,618 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,618 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,618 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,618 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,618 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,619 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,619 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,619 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,619 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,619 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:26:45,619 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:26:45,621 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405621
2022-03-15T00:26:45,626 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,626 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,619 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:26:45,621 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405621
2022-03-15T00:26:45,619 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:26:45,632 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,632 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,632 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,632 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,633 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,633 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,633 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,633 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,632 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:26:45,632 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:26:45,633 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:26:45,633 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:26:45,635 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:26:45,635 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:26:45,635 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:26:45,635 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:26:45,635 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:26:45,635 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:26:45,635 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:26:45,635 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:26:45,636 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,636 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]41911
2022-03-15T00:26:45,636 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,636 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,637 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,637 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,637 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:26:45,637 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:26:45,643 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:26:45,643 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,644 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,645 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,645 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:26:45,645 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:26:45,645 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,645 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:26:45,645 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:26:45,648 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]41916
2022-03-15T00:26:45,648 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:26:45,648 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405648
2022-03-15T00:26:45,648 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405648
2022-03-15T00:26:45,648 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,648 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,648 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,648 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,648 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]41914
2022-03-15T00:26:45,654 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,654 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,654 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,654 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,655 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,655 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,655 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,655 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:26:45,655 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:26:45,655 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,655 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,656 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:26:45,655 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,655 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,656 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,656 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,656 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,656 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,656 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:26:45,657 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:26:45,657 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:26:45,657 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:26:45,657 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:26:45,657 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:26:45,657 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:26:45,657 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:26:45,657 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:26:45,657 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,658 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,659 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,668 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405668
2022-03-15T00:26:45,668 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,668 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:26:45,668 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405668
2022-03-15T00:26:45,668 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,669 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:26:45,668 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:26:45,669 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,669 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405669
2022-03-15T00:26:45,669 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405669
2022-03-15T00:26:45,668 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,669 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:26:45,668 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,672 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,672 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,669 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:26:45,672 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]41917
2022-03-15T00:26:45,672 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]41918
2022-03-15T00:26:45,672 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,675 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,675 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,675 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,675 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,672 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,675 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:26:45,675 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:26:45,675 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:26:45,675 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:26:45,677 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,677 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,677 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:26:45,677 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:26:45,677 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,677 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,677 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,677 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,677 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2022-03-15T00:26:45,678 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:26:45,678 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:26:45,678 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:26:45,678 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _get_class_entry_point
2022-03-15T00:26:45,678 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     raise ValueError("Expected only one class in custom service code or a function entry point {}".format(
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:26:45,678 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:26:45,678 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,679 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,679 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,680 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,680 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2022-03-15T00:26:45,680 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _get_class_entry_point
2022-03-15T00:26:45,680 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     raise ValueError("Expected only one class in custom service code or a function entry point {}".format(
2022-03-15T00:26:45,680 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - ValueError: Expected only one class in custom service code or a function entry point [<class 'handle.MatrixFactorization'>, <class 'handle.ModelHandler'>]
2022-03-15T00:26:45,680 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,681 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2022-03-15T00:26:45,681 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 145, in _get_class_entry_point
2022-03-15T00:26:45,681 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     raise ValueError("Expected only one class in custom service code or a function entry point {}".format(
2022-03-15T00:26:45,681 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - ValueError: Expected only one class in custom service code or a function entry point [<class 'handle.MatrixFactorization'>, <class 'handle.ModelHandler'>]
2022-03-15T00:26:45,683 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,683 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,683 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,683 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,683 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,683 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,683 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405683
2022-03-15T00:26:45,683 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405683
2022-03-15T00:26:45,683 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,683 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,683 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,683 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,683 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,683 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,683 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,683 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,683 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,687 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:26:45,687 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:26:45,688 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405688
2022-03-15T00:26:45,688 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318405688
2022-03-15T00:26:45,688 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:26:45,688 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:26:45,688 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:26:45,688 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:26:45,688 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:26:45,688 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:26:45,688 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:26:45,694 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,694 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:26:45,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,696 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:26:45,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,696 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,696 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,696 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,696 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:26:45,696 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,696 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,696 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,696 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,696 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,696 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,696 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,697 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,696 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:26:45,697 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,697 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:26:45,697 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:26:45,697 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:26:45,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,697 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:26:45,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:26:45,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:26:45,697 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,697 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:26:45,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:26:45,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:26:45,697 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:26:45,697 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:26:45,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:26:45,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:26:45,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:26:45,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:26:45,698 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:26:45,698 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:26:45,698 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:26:45,698 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:26:45,698 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:26:45,700 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,700 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:26:45,700 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 104, in load
2022-03-15T00:26:45,700 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:26:45,700 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:26:45,700 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:31:07,845 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:31:07,845 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:31:07,883 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:31:07,883 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:31:07,915 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315002646624-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:31:07,915 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315002646624-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:31:07,921 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315002646624-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318406624,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:31:07,921 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315002646624-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318406624,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:31:07,924 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315002646624-shutdown.cfg
2022-03-15T00:31:07,924 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315002646624-shutdown.cfg
2022-03-15T00:31:07,924 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315002646624-shutdown.cfg validated successfully
2022-03-15T00:31:07,924 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315002646624-shutdown.cfg validated successfully
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:31:08,035 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:31:08,035 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:31:08,035 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:31:08,041 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:31:08,041 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:31:08,042 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:31:08,041 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:31:08,042 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:31:08,042 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:31:08,041 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:31:08,042 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:31:08,041 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:31:08,041 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:31:08,041 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:31:08,041 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:31:08,042 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:31:08,042 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:31:08,045 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:31:08,045 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:31:08,064 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:31:08,064 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:31:08,187 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:31:08,187 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:31:08,187 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:31:08,187 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:31:08,191 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:31:08,191 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:31:08,191 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:31:08,191 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:31:08,194 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:31:08,194 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:31:08,429 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:31:08,429 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:31:08,476 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:08,477 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.86663055419922|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:08,478 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.56509017944336|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:08,478 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:08,478 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2860.734375|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:08,478 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5218.671875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:08,478 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.5|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318668
2022-03-15T00:31:09,497 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,498 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,497 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,497 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,497 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,504 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42007
2022-03-15T00:31:09,497 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,504 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42003
2022-03-15T00:31:09,504 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42005
2022-03-15T00:31:09,504 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,504 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42002
2022-03-15T00:31:09,497 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,504 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,504 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42001
2022-03-15T00:31:09,504 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42004
2022-03-15T00:31:09,497 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:09,504 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,504 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,504 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,504 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,505 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,505 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,504 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42000
2022-03-15T00:31:09,505 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,505 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,505 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,505 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,505 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,505 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42006
2022-03-15T00:31:09,505 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,505 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,505 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:09,505 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:31:09,505 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:09,507 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:31:09,507 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:31:09,507 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:31:09,507 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:31:09,507 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:31:09,507 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:31:09,507 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:31:09,507 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:31:09,507 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:31:09,507 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:31:09,507 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:31:09,507 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:31:09,507 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:31:09,507 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:31:09,507 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:31:09,507 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:31:09,550 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:31:09,550 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:31:09,550 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:31:09,550 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:31:09,550 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:31:09,550 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:31:09,550 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:31:09,550 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:31:09,552 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,552 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318669552
2022-03-15T00:31:09,596 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,597 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,600 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,602 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,602 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,602 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,603 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,603 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,615 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,615 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,616 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,616 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,615 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,616 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,616 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,616 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,615 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,638 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,638 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,644 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,644 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,615 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,645 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,645 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,646 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,646 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,646 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,646 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,647 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,647 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,647 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,648 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,661 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,687 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,694 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,662 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,662 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,647 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,704 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,699 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,698 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,715 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,715 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,698 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/f1df7fbe82db403d84d3f54b9109fb08/handle.py", line 4, in <module>
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     import MatrixFactorization
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'MatrixFactorization'
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:31:09,716 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:31:09,717 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:31:09,717 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-03-15T00:31:09,698 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,718 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,718 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,718 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,718 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,715 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,662 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,662 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,698 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:09,718 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,697 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,717 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-03-15T00:31:09,719 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,719 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,694 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,719 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,719 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,719 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,719 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-03-15T00:31:09,720 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,720 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,720 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,720 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,720 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,720 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,687 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,720 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,719 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,720 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,720 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,661 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,720 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,720 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,721 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,721 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,721 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,721 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,721 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,721 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,648 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,720 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,715 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,714 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,718 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,720 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,704 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:09,720 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,722 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,722 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:09,728 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,729 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:09,728 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-03-15T00:31:09,729 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:09,729 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/f1df7fbe82db403d84d3f54b9109fb08/handle.py", line 4, in <module>
2022-03-15T00:31:09,729 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     import MatrixFactorization
2022-03-15T00:31:09,729 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'MatrixFactorization'
2022-03-15T00:31:09,729 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:09,729 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:09,741 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,748 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,748 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,748 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,748 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,749 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,749 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,749 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,720 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,720 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,718 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,749 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,749 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,718 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,749 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,749 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,749 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,749 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,750 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,750 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,749 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,750 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:31:09,750 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:31:09,750 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,750 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,750 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:31:09,750 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:31:09,750 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:31:09,750 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:31:09,750 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:31:09,751 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:31:09,751 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:31:09,721 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,721 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,755 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,755 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,755 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,755 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,722 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,722 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,756 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,756 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,756 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,756 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,756 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:31:09,756 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:31:09,756 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:31:09,756 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:31:09,756 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:31:09,756 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:31:09,756 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:31:09,756 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:31:09,757 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:31:09,757 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:31:09,757 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:31:09,757 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:31:09,757 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:31:09,757 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:31:09,757 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:31:09,757 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:31:09,757 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,757 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,758 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:31:09,758 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:31:09,758 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:31:09,758 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:31:09,699 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,699 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,759 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,759 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,759 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,759 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,760 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:31:09,760 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:31:09,760 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:31:09,760 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:09,760 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:31:09,760 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:31:09,760 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:31:09,760 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:31:09,760 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:31:09,760 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:09,761 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,761 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,761 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:09,761 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,761 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:09,761 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,761 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:09,762 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:09,719 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,763 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:31:09,763 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:31:09,763 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:31:09,719 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,763 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:09,763 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:09,763 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,763 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:09,763 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,763 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:31:09,763 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:31:09,721 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,721 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,764 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,763 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,763 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,764 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,764 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,764 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:31:09,764 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:31:09,764 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,764 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,764 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:31:09,764 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:31:09,764 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:31:09,764 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:31:09,764 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:31:09,764 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:31:09,764 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:31:09,764 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:31:09,764 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:31:09,764 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,765 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:31:09,764 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:31:09,765 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:31:09,765 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:31:09,765 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:09,765 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,772 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:31:09,765 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:31:09,772 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:31:09,772 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:09,720 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,772 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:09,720 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:09,772 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,772 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/f1df7fbe82db403d84d3f54b9109fb08/handle.py", line 4, in <module>
2022-03-15T00:31:09,772 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,772 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     import MatrixFactorization
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'MatrixFactorization'
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:31:09,772 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:31:09,772 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:09,772 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:31:09,772 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:31:10,756 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:31:10,756 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:31:10,758 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:31:10,758 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:31:10,759 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:31:10,759 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:31:10,757 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:31:10,757 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:31:10,762 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:31:10,762 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:31:10,766 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:31:10,766 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:31:10,774 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:31:10,774 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:31:10,774 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:31:10,774 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:31:11,861 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,861 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42011
2022-03-15T00:31:11,861 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,861 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,863 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,863 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,863 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:31:11,863 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:31:11,866 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,866 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42015
2022-03-15T00:31:11,866 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,866 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,870 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,870 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,870 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:31:11,870 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:31:11,875 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:31:11,876 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671876
2022-03-15T00:31:11,876 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671876
2022-03-15T00:31:11,887 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,889 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42012
2022-03-15T00:31:11,889 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,889 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,887 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,889 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671889
2022-03-15T00:31:11,889 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,887 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:31:11,899 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,899 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,889 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,889 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42016
2022-03-15T00:31:11,908 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:31:11,908 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:31:11,908 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,908 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,908 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,908 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,889 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671889
2022-03-15T00:31:11,908 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,908 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,892 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:11,909 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:11,908 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,908 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,909 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:31:11,909 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,909 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,909 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,909 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,909 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:31:11,911 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:31:11,911 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:31:11,911 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:31:11,911 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:31:11,911 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:31:11,911 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:11,911 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:11,911 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:31:11,911 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:11,920 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,920 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42013
2022-03-15T00:31:11,920 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,921 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,921 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:31:11,921 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:31:11,922 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,922 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,922 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:31:11,922 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:31:11,923 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:31:11,923 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:31:11,930 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,931 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,931 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671931
2022-03-15T00:31:11,931 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671931
2022-03-15T00:31:11,932 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,934 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,934 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,934 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,934 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:11,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:11,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:11,935 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:11,938 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42010
2022-03-15T00:31:11,938 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,938 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,938 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,938 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:11,942 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671942
2022-03-15T00:31:11,942 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671942
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:11,938 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/f1df7fbe82db403d84d3f54b9109fb08/handle.py", line 4, in <module>
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     import MatrixFactorization
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'MatrixFactorization'
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:31:11,942 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:31:11,946 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,946 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,947 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,947 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,947 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:31:11,946 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,947 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:31:11,947 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:31:11,947 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:31:11,947 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:31:11,948 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:31:11,947 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,947 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,948 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,948 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,948 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,948 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,948 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42014
2022-03-15T00:31:11,948 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42009
2022-03-15T00:31:11,949 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,949 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,949 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:31:11,949 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,949 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,949 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:31:11,950 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:31:11,951 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,950 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,951 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,951 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:31:11,950 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:31:11,951 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:31:11,951 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,949 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:31:11,951 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:31:11,951 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:31:11,950 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,951 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:31:11,951 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:31:11,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,951 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:31:11,951 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:31:11,951 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:31:11,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,951 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,951 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,951 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,951 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,951 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:31:11,951 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:31:11,952 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:31:11,952 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:31:11,952 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:31:11,952 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:31:11,952 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:31:11,952 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:11,953 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:11,955 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,955 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,956 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,956 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,956 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,956 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,956 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,956 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,956 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,956 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,956 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:31:11,956 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:31:11,956 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:31:11,956 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:31:11,956 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:31:11,956 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:31:11,956 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:31:11,956 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:31:11,961 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,961 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:31:11,961 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:31:11,961 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:31:11,961 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:31:11,961 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:31:11,962 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671962
2022-03-15T00:31:11,962 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671962
2022-03-15T00:31:11,963 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671963
2022-03-15T00:31:11,963 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671963
2022-03-15T00:31:11,963 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:11,963 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:31:11,963 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:31:11,965 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671965
2022-03-15T00:31:11,965 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671965
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,968 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:11,968 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,968 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:11,968 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:11,968 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,968 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,968 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,968 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,978 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,978 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,978 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,978 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,981 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:31:11,981 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:31:11,981 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:31:11,981 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:31:11,981 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:31:11,981 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:31:11,981 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:31:11,981 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:31:11,983 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,983 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,984 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,984 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,984 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671971
2022-03-15T00:31:11,984 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318671971
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:11,984 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,984 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:11,984 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,984 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,984 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,984 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,984 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,984 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,986 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:11,986 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:31:11,986 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:31:11,986 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,986 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,986 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,986 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:11,986 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:11,986 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,986 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,986 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:31:11,986 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:31:11,987 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:31:11,987 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:31:11,987 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:31:11,987 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:31:11,986 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:31:11,986 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:31:11,987 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:11,987 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:31:11,987 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:31:11,987 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,987 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,988 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,988 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,988 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,988 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,988 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,988 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,988 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:31:11,988 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:31:11,988 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:31:11,988 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:31:11,990 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:31:11,990 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:31:11,990 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:31:11,990 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,990 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:31:11,990 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:31:11,990 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:31:11,991 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:31:11,992 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:31:11,992 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:31:11,992 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:31:11,993 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:31:11,993 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,993 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:31:11,993 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,993 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:31:11,993 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,993 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:31:11,993 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,993 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:31:11,993 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:31:11,993 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:31:11,993 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/f1df7fbe82db403d84d3f54b9109fb08/handle.py", line 4, in <module>
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     import MatrixFactorization
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'MatrixFactorization'
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:31:11,994 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:31:11,994 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:31:11,994 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:31:11,994 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:31:11,995 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:31:11,995 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:31:11,994 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:31:11,995 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:31:11,995 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:31:12,925 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:31:12,925 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:31:12,957 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:31:12,957 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:31:12,957 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:31:12,957 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:31:12,957 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:31:12,957 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:31:12,987 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:31:12,987 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:31:12,987 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:31:12,987 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:31:12,992 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:31:12,992 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:31:13,000 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:31:13,000 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:32:05,849 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:32:05,849 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:32:05,886 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:32:05,886 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:32:05,920 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003113487-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:32:05,920 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003113487-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:32:05,925 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003113487-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318673487,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:32:05,925 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003113487-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318673487,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:32:05,928 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003113487-shutdown.cfg
2022-03-15T00:32:05,928 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003113487-shutdown.cfg
2022-03-15T00:32:05,929 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003113487-shutdown.cfg validated successfully
2022-03-15T00:32:05,929 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003113487-shutdown.cfg validated successfully
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:32:06,045 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:32:06,045 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:32:06,045 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:32:06,051 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:32:06,051 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:32:06,051 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:32:06,051 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:32:06,051 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:32:06,051 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:32:06,051 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:32:06,052 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:32:06,051 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:32:06,051 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:32:06,052 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:32:06,051 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:32:06,052 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:32:06,052 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:32:06,055 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:32:06,055 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:32:06,063 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:32:06,063 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:32:06,169 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:32:06,169 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:32:06,169 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:32:06,169 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:32:06,171 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:32:06,171 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:32:06,172 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:32:06,172 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:32:06,172 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:32:06,172 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:32:06,595 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:32:06,595 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:32:06,642 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:06,643 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.86682510375977|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:06,643 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.5648956298828|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:06,643 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:06,643 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2825.453125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:06,643 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5167.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:06,643 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.8|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318726
2022-03-15T00:32:07,631 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,631 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,631 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,631 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,631 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,631 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42070
2022-03-15T00:32:07,631 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,631 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,632 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42069
2022-03-15T00:32:07,631 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42071
2022-03-15T00:32:07,632 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42065
2022-03-15T00:32:07,631 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42068
2022-03-15T00:32:07,631 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:32:07,632 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42066
2022-03-15T00:32:07,632 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,632 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,632 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,632 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,632 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42072
2022-03-15T00:32:07,632 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,632 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42067
2022-03-15T00:32:07,633 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,633 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:32:07,632 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,632 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,632 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,633 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,633 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,633 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,633 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:32:07,633 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:32:07,637 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:32:07,637 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:32:07,637 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:32:07,637 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:32:07,637 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:32:07,637 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:32:07,637 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:32:07,637 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:32:07,637 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:32:07,637 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:32:07,637 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:32:07,637 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:32:07,637 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:32:07,637 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:32:07,637 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:32:07,637 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:32:07,682 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:32:07,683 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:32:07,683 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:32:07,683 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:32:07,684 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:32:07,684 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:32:07,684 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:32:07,684 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:32:07,685 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,685 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318727685
2022-03-15T00:32:07,725 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,726 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,728 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,729 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,732 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,732 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,733 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,733 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:32:07,746 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,746 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,746 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,746 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,747 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,746 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,747 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,747 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:32:07,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:32:07,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:32:07,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:32:07,748 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:32:07,749 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,749 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,749 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,749 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,753 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,746 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,746 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,746 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,754 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,755 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,755 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,755 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,755 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,758 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,758 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,749 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:32:07,759 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,759 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,758 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,759 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:32:07,761 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,761 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,759 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,758 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,759 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,762 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,759 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,759 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,764 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,763 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,764 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:32:07,764 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,762 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,762 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,763 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,764 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,764 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,764 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,759 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:32:07,765 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,765 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:32:07,769 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,769 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:32:07,769 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,770 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:32:07,770 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,772 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,772 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,772 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:32:07,772 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:32:07,772 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:32:07,772 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:32:07,773 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:32:07,773 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,773 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,773 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:32:07,764 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,764 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,765 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,764 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,781 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,781 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,765 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,764 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,781 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,781 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,781 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,781 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,781 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,781 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,782 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,782 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,782 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,782 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,787 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:32:07,760 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,760 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,788 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,792 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:32:07,792 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:32:07,792 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:32:07,792 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:32:07,792 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/34a610b8dd5e4de183c8e30e05520839/handle.py", line 4, in <module>
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     from model import MatrixFactorization
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:32:07,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-03-15T00:32:07,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-03-15T00:32:07,788 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,795 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,795 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,790 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:32:07,790 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:32:07,790 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:32:07,796 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:32:07,796 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:32:07,790 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:32:07,799 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:32:07,799 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:32:07,799 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:32:07,789 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:32:07,799 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:32:07,799 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:32:07,789 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:32:07,800 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:32:07,800 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:32:07,795 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:32:07,799 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:32:07,792 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:32:07,792 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:32:07,800 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:32:07,800 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:32:07,800 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:32:07,800 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:32:07,795 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:32:07,800 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:32:07,800 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:32:07,801 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:32:07,801 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:32:07,765 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,765 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,760 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,760 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,804 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,804 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,805 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,805 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,804 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,804 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,805 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,805 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,806 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:32:07,806 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:32:07,806 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:32:07,806 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:32:07,806 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:32:07,806 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:32:07,807 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:32:07,807 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:32:07,806 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:32:07,806 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:32:07,808 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:32:07,808 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:32:07,808 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:32:07,808 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-03-15T00:32:07,808 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:32:07,808 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:32:07,808 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:32:07,808 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:32:07,808 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/34a610b8dd5e4de183c8e30e05520839/handle.py", line 4, in <module>
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     from model import MatrixFactorization
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:32:07,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-03-15T00:32:07,764 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,764 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,813 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,813 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,814 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,814 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,814 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:32:07,814 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:32:07,814 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:32:07,814 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:32:07,814 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:32:07,814 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:32:07,814 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:32:07,814 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:32:07,815 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:32:07,815 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:32:07,815 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:32:07,815 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:32:07,815 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:32:07,815 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:32:07,764 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,764 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:32:07,822 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:32:07,822 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,822 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:32:07,822 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:32:07,822 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:32:07,822 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-03-15T00:32:07,822 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handle'
2022-03-15T00:32:07,822 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,822 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:32:07,823 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:32:07,823 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:32:07,823 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:32:07,823 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:32:07,823 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:32:07,823 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:32:07,823 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:32:07,823 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:32:07,823 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:32:07,823 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:32:08,807 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:32:08,807 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:32:08,816 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:32:08,816 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:32:08,816 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:32:08,816 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:32:08,816 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:32:08,816 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:32:08,816 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:32:08,816 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:32:08,816 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:32:08,816 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:32:08,816 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:32:08,816 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:32:08,824 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:32:08,824 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:36:21,682 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:36:21,682 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:36:21,721 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:36:21,721 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:36:21,752 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003209765-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:36:21,752 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003209765-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:36:21,757 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003209765-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318729765,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:36:21,757 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003209765-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318729765,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:36:21,761 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003209765-shutdown.cfg
2022-03-15T00:36:21,761 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003209765-shutdown.cfg
2022-03-15T00:36:21,761 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003209765-shutdown.cfg validated successfully
2022-03-15T00:36:21,761 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003209765-shutdown.cfg validated successfully
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:36:21,884 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:36:21,884 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:36:21,884 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:36:21,894 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:36:21,894 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:36:21,894 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:36:21,894 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:36:21,894 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:36:21,894 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:36:21,894 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:36:21,894 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:36:21,894 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:36:21,894 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:36:21,894 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:36:21,894 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:36:21,894 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:36:21,894 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:36:21,894 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:36:21,894 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:36:21,898 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:36:21,898 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:36:22,025 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:36:22,025 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:36:22,025 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:36:22,025 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:36:22,026 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:36:22,026 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:36:22,026 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:36:22,026 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:36:22,027 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:36:22,027 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:36:22,343 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:36:22,343 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:36:22,407 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:22,408 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.86222076416016|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:22,408 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.56949996948242|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:22,408 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:22,408 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2832.640625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:22,408 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5245.6875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:22,408 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.7|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647318982
2022-03-15T00:36:23,246 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,246 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,246 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,247 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42154
2022-03-15T00:36:23,247 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42156
2022-03-15T00:36:23,246 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,246 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,246 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,247 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,247 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42153
2022-03-15T00:36:23,247 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42158
2022-03-15T00:36:23,247 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,247 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,247 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,247 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,247 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,247 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42159
2022-03-15T00:36:23,248 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,246 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,247 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,248 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,247 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,247 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,248 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,248 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,248 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,247 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42160
2022-03-15T00:36:23,246 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:36:23,248 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42157
2022-03-15T00:36:23,248 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,248 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,248 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42155
2022-03-15T00:36:23,247 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,248 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,248 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:36:23,248 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,248 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:36:23,248 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:36:23,250 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:36:23,250 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:36:23,250 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:36:23,250 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:36:23,250 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:36:23,250 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:36:23,250 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:36:23,250 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:36:23,250 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:36:23,251 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:36:23,250 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:36:23,251 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:36:23,250 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:36:23,250 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:36:23,250 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:36:23,250 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:36:23,294 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:36:23,294 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:36:23,294 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:36:23,294 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:36:23,295 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:36:23,294 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:36:23,294 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:36:23,295 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:36:23,296 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,296 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647318983296
2022-03-15T00:36:23,350 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,351 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,352 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,353 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,354 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,355 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,355 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,355 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:36:23,362 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,364 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,366 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,366 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,364 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,373 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,374 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:36:23,375 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,375 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,366 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,366 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,376 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,376 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,367 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,367 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,377 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,377 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,377 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,377 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,377 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,377 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,377 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,377 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,377 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,377 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,378 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:36:23,379 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,379 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,387 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,387 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,404 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,377 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,377 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,439 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,439 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,439 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,439 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,446 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,447 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:36:23,459 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:36:23,459 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:36:23,459 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:36:23,459 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:36:23,460 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:36:23,460 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:36:23,464 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:36:23,464 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:36:23,467 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,467 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,467 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,468 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,470 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:36:23,487 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,487 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,487 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,487 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:36:23,489 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,489 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,489 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,489 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,489 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,489 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,489 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,489 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,489 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:36:23,489 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,490 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,490 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,490 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,490 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,490 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,490 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,490 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:36:23,490 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:36:23,492 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:36:23,492 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:36:23,490 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:36:23,490 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:36:23,494 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:36:23,494 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:36:23,494 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:36:23,494 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:36:23,499 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,499 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:36:23,499 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:36:23,499 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:36:23,500 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:36:23,500 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:36:23,507 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,376 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,507 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,507 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,508 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,376 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,508 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,508 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,508 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,508 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,508 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,508 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,508 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:36:23,508 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,508 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,508 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,508 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:36:23,508 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:36:23,377 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,377 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,508 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:36:23,508 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,508 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,509 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,509 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,509 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,509 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,508 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:36:23,509 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,509 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:36:23,509 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,509 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:36:23,509 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:36:23,509 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,509 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:36:23,509 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:36:23,509 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:36:23,509 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:36:23,509 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,509 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:36:23,509 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:36:23,509 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:36:23,387 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,387 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,512 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:36:23,512 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,512 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,512 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-03-15T00:36:23,512 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,512 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,512 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:36:23,512 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/3b23f834a1b3479ba129051b61aa1ccc/handle.py", line 4, in <module>
2022-03-15T00:36:23,512 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     from model import MatrixFactorization
2022-03-15T00:36:23,509 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:36:23,512 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:36:23,512 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:36:23,512 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:36:23,512 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-03-15T00:36:23,512 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:36:23,512 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - 
2022-03-15T00:36:23,513 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:36:23,513 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:36:23,512 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:36:23,513 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,514 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-03-15T00:36:23,520 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:36:23,377 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,520 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:36:23,377 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-03-15T00:36:23,521 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-03-15T00:36:23,521 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-03-15T00:36:23,521 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-03-15T00:36:23,521 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:36:23,521 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:36:23,521 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:36:23,521 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:36:23,521 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:36:23,521 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:36:23,522 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:36:23,522 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:36:23,379 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,379 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:36:23,523 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:36:23,523 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,523 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:36:23,523 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:36:23,523 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-03-15T00:36:23,523 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:36:23,523 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-03-15T00:36:23,523 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-03-15T00:36:23,523 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,523 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:36:23,523 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-03-15T00:36:23,523 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:36:23,523 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:36:23,523 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:36:23,523 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:36:23,523 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-03-15T00:36:23,523 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:36:23,523 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handle'
2022-03-15T00:36:23,524 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:36:23,524 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:36:23,524 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:36:23,524 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:36:23,524 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:36:23,524 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:36:23,524 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:36:23,524 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:36:23,524 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:36:23,524 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:36:24,479 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:36:24,479 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:36:24,496 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:36:24,496 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:36:24,496 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:36:24,496 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:36:24,511 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:36:24,511 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:36:24,511 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:36:24,511 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:36:24,514 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:36:24,514 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:36:24,524 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:36:24,524 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:36:24,527 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:36:24,527 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:37:29,290 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:37:29,290 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:37:29,327 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:37:29,327 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:37:29,358 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003625150-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:37:29,358 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003625150-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:37:29,364 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003625150-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318985151,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:37:29,364 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003625150-shutdown.cfg",
  "modelCount": 1,
  "created": 1647318985151,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:37:29,367 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003625150-shutdown.cfg
2022-03-15T00:37:29,367 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003625150-shutdown.cfg
2022-03-15T00:37:29,368 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003625150-shutdown.cfg validated successfully
2022-03-15T00:37:29,368 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003625150-shutdown.cfg validated successfully
2022-03-15T00:37:29,485 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:37:29,485 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:37:29,485 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:37:29,485 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:37:29,485 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:37:29,485 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:37:29,486 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:37:29,486 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:37:29,486 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:37:29,486 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:37:29,492 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:37:29,492 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:37:29,492 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:37:29,492 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:37:29,492 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:37:29,492 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:37:29,492 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:37:29,492 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:37:29,492 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:37:29,492 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:37:29,492 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:37:29,492 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:37:29,492 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:37:29,492 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:37:29,492 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:37:29,492 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:37:29,494 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:37:29,494 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:37:29,654 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:37:29,654 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:37:29,654 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:37:29,654 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:37:29,654 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:37:29,654 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:37:29,655 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:37:29,655 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:37:29,655 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:37:29,655 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:37:30,054 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:37:30,054 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:37:30,094 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:30,095 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8614616394043|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:30,095 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.57025909423828|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:30,095 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:30,095 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2690.203125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:30,096 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5120.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:30,096 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.6|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319050
2022-03-15T00:37:31,009 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,009 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,010 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,009 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,010 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42238
2022-03-15T00:37:31,010 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42232
2022-03-15T00:37:31,010 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42237
2022-03-15T00:37:31,009 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,010 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,010 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42234
2022-03-15T00:37:31,009 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,010 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,010 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42231
2022-03-15T00:37:31,010 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,009 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:37:31,010 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42235
2022-03-15T00:37:31,010 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,010 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,010 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42236
2022-03-15T00:37:31,010 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,010 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42233
2022-03-15T00:37:31,011 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,011 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,010 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,011 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,011 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,011 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,010 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,010 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:37:31,011 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,010 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,010 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:37:31,011 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,012 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:37:31,013 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:37:31,013 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:37:31,013 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:37:31,013 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:37:31,013 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:37:31,013 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:37:31,013 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:37:31,013 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:37:31,013 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:37:31,013 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:37:31,013 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:37:31,013 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:37:31,013 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:37:31,013 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:37:31,013 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:37:31,013 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:37:31,041 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:37:31,042 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:37:31,042 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:37:31,043 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,043 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319051043
2022-03-15T00:37:31,062 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:37:31,086 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:37:31,090 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,090 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,091 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,090 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,090 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,096 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:37:31,096 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:37:31,096 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:37:31,096 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,097 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,096 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:37:31,103 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:37:31,104 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:37:31,104 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:37:31,104 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,104 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,104 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:37:31,104 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:37:31,104 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:37:31,104 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,113 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:37:31,114 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:37:31,104 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,104 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:37:31,154 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,154 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,154 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:37:31,110 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,155 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:37:31,155 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:37:31,155 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:37:31,155 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,155 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,155 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:37:31,156 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:37:31,156 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:37:31,156 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:37:31,156 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:37:31,157 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:37:31,161 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:37:31,154 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:37:31,171 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:37:31,172 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:37:31,172 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:37:31,172 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:37:31,172 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:37:31,172 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:37:31,183 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:37:31,183 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:37:31,183 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/private/var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/models/670405a11ed74d8faa469d72dfaf87e5/handle.py", line 31, in initialize
2022-03-15T00:37:31,183 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     from model import MatrixFactorization
2022-03-15T00:37:31,183 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2022-03-15T00:37:31,182 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,185 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,182 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,185 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,186 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,186 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,186 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,186 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,186 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,186 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,186 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,186 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,199 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,199 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,200 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,200 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,199 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,199 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,201 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,201 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,201 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:37:31,201 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:37:31,201 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:37:31,202 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:37:31,201 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:37:31,202 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:37:31,202 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:37:31,202 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:37:31,203 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:37:31,203 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:37:31,207 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,207 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,208 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,208 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,208 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,208 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,208 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,208 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,208 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,208 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,208 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:37:31,208 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:37:31,208 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:37:31,209 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:37:31,209 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:37:31,209 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:37:31,209 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:37:31,208 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:37:31,225 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,225 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,226 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,226 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,227 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,227 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,227 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,227 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,227 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,227 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,229 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:37:31,229 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:37:31,230 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:37:31,230 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:37:31,231 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:37:31,231 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:37:31,230 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:37:31,230 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:37:31,231 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:37:31,231 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:37:31,160 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,160 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,236 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,236 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,236 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,236 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,236 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,236 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,236 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:37:31,236 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:37:31,236 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:37:31,236 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:37:31,236 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:37:31,236 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:37:31,236 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:37:31,236 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:37:31,160 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,160 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,246 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,246 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,246 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,246 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,246 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,246 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,246 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,246 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,246 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,246 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,246 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,246 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,247 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,247 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,247 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,247 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,247 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:37:31,247 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:37:31,247 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:37:31,247 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:37:31,247 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:37:31,247 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:37:31,247 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:37:31,247 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:37:31,247 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:37:31,256 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,256 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:37:31,262 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:37:31,262 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,262 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:37:31,262 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:37:31,262 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:37:31,262 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:37:31,262 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:37:31,262 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:37:31,262 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,262 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:37:31,262 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,262 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:37:31,262 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,262 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:37:31,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:37:31,263 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:37:31,263 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:37:31,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:37:31,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:37:31,263 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:37:31,263 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:37:31,263 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:37:31,267 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:37:31,267 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:37:31,267 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:37:31,267 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,267 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:37:31,267 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:37:31,268 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:37:31,268 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:37:31,268 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:37:31,268 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:37:31,268 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:37:31,268 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:39:44,035 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:39:44,035 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:39:44,071 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:39:44,071 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:39:44,103 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003731268-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:39:44,103 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003731268-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:39:44,109 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003731268-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319051269,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:39:44,109 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003731268-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319051269,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:39:44,112 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003731268-shutdown.cfg
2022-03-15T00:39:44,112 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003731268-shutdown.cfg
2022-03-15T00:39:44,112 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003731268-shutdown.cfg validated successfully
2022-03-15T00:39:44,112 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003731268-shutdown.cfg validated successfully
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:39:44,225 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:39:44,225 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:39:44,225 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:39:44,231 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:39:44,231 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:39:44,231 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:39:44,231 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:39:44,231 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:39:44,231 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:39:44,231 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:39:44,231 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:39:44,232 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:39:44,232 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:39:44,231 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:39:44,231 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:39:44,231 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:39:44,231 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:39:44,235 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:39:44,235 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:39:44,241 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:39:44,241 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:39:44,358 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:39:44,358 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:39:44,358 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:39:44,358 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:39:44,359 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:39:44,359 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:39:44,359 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:39:44,359 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:39:44,360 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:39:44,360 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:39:44,853 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:39:44,853 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:39:44,897 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:44,897 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:222.8583869934082|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:44,898 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:237.57333374023438|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:44,899 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.6|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:44,899 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2959.46875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:44,899 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5281.75|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:44,900 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:81.9|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319184
2022-03-15T00:39:45,625 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,624 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,625 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,625 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,625 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,625 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42300
2022-03-15T00:39:45,625 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,625 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,625 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42303
2022-03-15T00:39:45,625 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42302
2022-03-15T00:39:45,625 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42306
2022-03-15T00:39:45,626 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,625 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:39:45,626 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42301
2022-03-15T00:39:45,626 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,626 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,626 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42307
2022-03-15T00:39:45,626 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,625 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42305
2022-03-15T00:39:45,626 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42304
2022-03-15T00:39:45,627 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,626 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,626 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,627 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,627 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,627 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,627 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,627 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:39:45,627 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,627 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,627 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,627 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:39:45,627 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,626 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,627 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:39:45,632 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:39:45,632 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:39:45,632 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:39:45,632 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:39:45,632 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:39:45,632 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:39:45,632 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:39:45,632 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:39:45,632 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:39:45,632 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:39:45,632 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:39:45,632 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:39:45,632 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:39:45,632 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:39:45,632 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:39:45,632 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:39:45,671 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:39:45,671 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:39:45,671 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:39:45,671 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:39:45,672 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:39:45,672 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:39:45,672 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:39:45,672 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:39:45,673 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,673 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319185673
2022-03-15T00:39:45,728 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,728 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,740 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,745 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,751 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,752 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,752 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,753 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:39:45,805 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:39:45,808 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,809 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,809 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,809 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,809 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,809 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,809 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,809 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,809 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,809 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,809 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,809 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:39:45,809 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,809 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,809 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,809 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,809 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:39:45,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:39:45,810 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:39:45,809 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:39:45,810 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:39:45,813 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:39:45,813 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:39:45,813 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:39:45,813 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:39:45,813 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:39:45,813 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:39:45,810 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,813 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,816 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,813 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,811 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:39:45,816 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,818 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,818 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,819 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,819 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,819 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,819 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,819 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,819 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,820 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,820 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,820 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,820 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,820 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,820 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,820 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,820 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,821 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:39:45,838 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,838 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,838 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,838 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,840 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,840 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,843 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,843 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:39:45,840 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,840 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,819 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,819 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,820 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,820 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,861 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,861 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,862 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,862 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,820 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,820 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,864 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,864 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,864 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,864 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,849 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,849 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:39:45,867 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,867 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,867 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,819 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,819 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,868 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,868 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,868 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,868 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,820 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,820 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,840 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:39:45,871 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:39:45,871 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:39:45,871 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:39:45,871 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:39:45,872 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:39:45,872 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:39:45,873 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:39:45,872 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,873 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:39:45,871 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,871 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,873 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:39:45,873 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:39:45,874 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:39:45,874 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:39:45,876 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:39:45,840 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,840 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,876 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,876 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,876 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,876 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,871 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:39:45,871 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:39:45,876 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:39:45,876 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:39:45,877 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:39:45,877 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:39:45,873 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:39:45,877 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:39:45,877 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:39:45,867 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,884 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,884 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,853 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,853 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:39:45,887 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,887 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,887 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,887 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,888 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:39:45,888 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:39:45,888 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:39:45,888 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:39:45,888 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:39:45,888 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:39:45,888 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:39:45,855 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,855 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:39:45,889 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,889 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,889 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:39:45,887 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:39:45,887 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:39:45,889 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:39:45,888 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:39:45,883 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:39:45,889 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:39:45,890 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:39:45,890 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:39:45,876 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:39:45,873 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,890 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:39:45,890 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:39:45,884 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:39:45,884 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:39:45,891 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:39:45,891 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:39:45,891 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:39:45,891 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:39:45,883 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:39:45,873 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:39:45,890 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:39:45,890 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:39:45,892 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:39:45,892 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:39:45,892 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:39:45,892 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:39:45,892 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:39:45,893 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:39:45,892 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:39:45,893 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:39:45,893 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:39:45,893 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:39:45,893 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:39:45,893 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:39:45,893 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,899 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:39:45,899 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:39:45,899 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:39:45,899 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:39:45,900 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:39:45,900 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:39:45,900 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:39:45,900 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:39:45,900 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:39:45,900 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:39:45,900 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:39:45,900 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:39:46,878 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:39:46,878 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:39:46,879 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:39:46,879 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:39:46,891 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:39:46,891 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:39:46,891 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:39:46,891 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:39:46,891 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:39:46,891 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:39:46,892 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:39:46,892 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:39:46,893 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:39:46,893 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:39:46,895 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:39:46,895 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:40:34,781 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:40:34,781 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:40:34,819 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:40:34,819 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:40:34,850 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003947980-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:40:34,850 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315003947980-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:40:34,856 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003947980-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319187981,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:40:34,856 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315003947980-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319187981,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:40:34,859 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003947980-shutdown.cfg
2022-03-15T00:40:34,859 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315003947980-shutdown.cfg
2022-03-15T00:40:34,859 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003947980-shutdown.cfg validated successfully
2022-03-15T00:40:34,859 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315003947980-shutdown.cfg validated successfully
2022-03-15T00:40:34,985 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:40:34,985 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:40:34,985 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:40:34,985 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:40:34,985 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:40:34,985 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:40:34,986 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:40:34,986 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:40:34,986 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:40:34,986 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:40:34,992 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:40:34,992 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:40:34,992 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:40:34,992 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:40:34,992 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:40:34,992 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:40:34,992 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:40:34,992 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:40:34,992 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:40:34,992 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:40:34,992 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:40:34,992 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:40:34,992 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:40:34,992 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:40:34,992 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:40:34,992 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:40:34,995 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:40:34,995 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:40:35,122 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:40:35,122 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:40:35,123 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:40:35,123 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:40:35,126 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:40:35,126 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:40:35,126 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:40:35,126 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:40:35,127 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:40:35,127 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:40:35,560 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:40:35,560 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:40:35,612 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:35,612 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:222.85894775390625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:35,613 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:237.57277297973633|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:35,614 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.6|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:35,614 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2685.953125|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:35,614 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5096.1875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:35,614 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.6|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319235
2022-03-15T00:40:36,591 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,591 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,591 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,591 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,591 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,591 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42382
2022-03-15T00:40:36,591 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,591 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,592 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42386
2022-03-15T00:40:36,592 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42383
2022-03-15T00:40:36,591 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:36,592 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,591 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42381
2022-03-15T00:40:36,592 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42384
2022-03-15T00:40:36,592 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,592 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42385
2022-03-15T00:40:36,592 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,592 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,591 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42387
2022-03-15T00:40:36,592 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,593 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,592 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42380
2022-03-15T00:40:36,592 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,593 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,593 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,593 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,593 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,593 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:36,592 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,593 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,593 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,593 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,592 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,593 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:36,593 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:40:36,595 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:40:36,595 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:40:36,595 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:40:36,595 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:40:36,595 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:40:36,595 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:40:36,595 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:40:36,595 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:40:36,595 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:40:36,595 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:40:36,595 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:40:36,595 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:40:36,595 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:40:36,595 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:40:36,595 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:40:36,595 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:40:36,637 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:40:36,637 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:40:36,637 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:40:36,637 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:40:36,638 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:40:36,638 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:40:36,638 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:40:36,639 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:40:36,640 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,640 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319236640
2022-03-15T00:40:36,684 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,688 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,693 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,694 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,694 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,694 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,694 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,695 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:36,731 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,731 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:36,732 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:36,733 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,743 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,743 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,743 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,743 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,743 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,743 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,744 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,743 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,744 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,744 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,744 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,744 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,744 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:36,744 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,744 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:36,744 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:36,744 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:36,778 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:36,838 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:36,838 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)
2022-03-15T00:40:36,851 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - RuntimeError: PytorchStreamReader failed locating file constants.pkl: file not found
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,852 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,853 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:36,853 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:36,853 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:36,853 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:36,854 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:40:36,854 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:40:36,854 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:40:36,854 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:40:36,854 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:40:36,857 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,857 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,859 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,859 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,860 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,860 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,870 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,870 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,879 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,860 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,860 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,879 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,879 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,879 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,879 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,880 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:40:36,880 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:40:36,880 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:40:36,880 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:40:36,880 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:40:36,880 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:40:36,870 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,870 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,882 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,882 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,882 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,882 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,879 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,883 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,883 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:36,884 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:36,884 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,884 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,884 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,884 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,885 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,885 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,885 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,885 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,885 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:40:36,885 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:40:36,885 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:40:36,885 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:40:36,886 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:40:36,886 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:40:36,887 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:40:36,880 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:40:36,887 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:40:36,880 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:40:36,889 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:36,889 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:40:36,889 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:40:36,887 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:40:36,887 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:40:36,880 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:40:36,887 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:40:36,887 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:40:36,890 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:40:36,890 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:40:36,880 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:40:36,890 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:40:36,889 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,890 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:40:36,889 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,890 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,890 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,890 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,890 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,890 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,891 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,890 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,890 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,890 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,891 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,891 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,892 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,892 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,892 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,892 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,892 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,892 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,892 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,892 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,892 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,892 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,892 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,891 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,894 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:40:36,894 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:40:36,892 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,894 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,894 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,895 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,895 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,895 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,895 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,894 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:40:36,894 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:40:36,895 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:40:36,895 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:40:36,895 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:40:36,895 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:40:36,895 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:40:36,895 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:40:36,896 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:40:36,896 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:40:36,896 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:40:36,896 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:40:36,896 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:40:36,896 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:40:36,896 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:40:36,896 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:40:36,896 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:40:36,895 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:40:36,895 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,895 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:40:36,895 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,898 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:40:36,898 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:40:36,896 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:40:36,898 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,898 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,899 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,899 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,899 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,899 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,899 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:40:36,899 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:40:36,899 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:40:36,899 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:40:36,899 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:40:36,899 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:40:36,899 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:40:36,899 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:40:36,900 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,900 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:36,900 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,900 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:36,901 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:36,901 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:40:36,901 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:40:36,901 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:40:36,901 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,901 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:36,901 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:36,901 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:36,901 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:40:36,901 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:36,901 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:40:36,901 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:40:36,901 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:40:36,901 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:36,901 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,901 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:36,909 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,909 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:36,909 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,909 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:40:36,910 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:40:36,910 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:36,910 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:40:36,910 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:36,910 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:36,910 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:40:36,910 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:40:36,910 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:40:37,888 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:40:37,888 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:40:37,892 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:40:37,892 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:40:37,894 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:40:37,894 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:40:37,896 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:40:37,896 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:40:37,896 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:40:37,896 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:40:37,899 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:40:37,899 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:40:37,899 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:40:37,899 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:40:37,913 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:40:37,913 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:40:39,057 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,057 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42389
2022-03-15T00:40:39,058 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,058 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,058 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,058 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:40:39,058 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:40:39,058 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,066 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,068 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239068
2022-03-15T00:40:39,068 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239068
2022-03-15T00:40:39,068 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:40:39,080 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42393
2022-03-15T00:40:39,080 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,080 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,081 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,081 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,081 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:40:39,081 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:40:39,082 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,082 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42392
2022-03-15T00:40:39,080 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,083 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42396
2022-03-15T00:40:39,084 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,084 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,084 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,084 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,084 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:40:39,084 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:40:39,082 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,084 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,087 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,087 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,087 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:40:39,087 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:40:39,097 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239097
2022-03-15T00:40:39,097 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239097
2022-03-15T00:40:39,099 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:40:39,100 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,101 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,103 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42390
2022-03-15T00:40:39,103 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:40:39,103 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,103 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,103 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239103
2022-03-15T00:40:39,103 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239103
2022-03-15T00:40:39,103 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,103 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:40:39,103 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239103
2022-03-15T00:40:39,103 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,103 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239103
2022-03-15T00:40:39,103 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:40:39,110 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:40:39,110 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,110 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42391
2022-03-15T00:40:39,110 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,110 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,110 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,111 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,111 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,111 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,113 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,113 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,114 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:40:39,114 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:40:39,114 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,114 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,116 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,116 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,116 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,116 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,116 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,116 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,116 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,116 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,118 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:40:39,118 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:40:39,118 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:40:39,118 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:40:39,118 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:40:39,118 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:40:39,118 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:40:39,121 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,118 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:40:39,122 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,122 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:40:39,122 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,122 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42395
2022-03-15T00:40:39,122 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,122 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,122 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,122 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,122 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:40:39,122 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:40:39,122 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,123 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,125 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,125 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239125
2022-03-15T00:40:39,125 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239125
2022-03-15T00:40:39,126 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,126 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,126 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42394
2022-03-15T00:40:39,126 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:40:39,126 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:40:39,126 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,126 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,126 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239126
2022-03-15T00:40:39,126 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239126
2022-03-15T00:40:39,127 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,127 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,127 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,127 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,128 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,127 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,132 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:40:39,132 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:40:39,132 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,132 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,133 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,132 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,133 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,126 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,126 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,134 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,134 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-03-15T00:40:39,134 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:40:39,134 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:40:39,135 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,135 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,135 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,135 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,135 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,135 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,135 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,135 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,135 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,135 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,135 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,135 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,135 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,135 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,135 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,135 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,126 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,137 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:40:39,137 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:40:39,137 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:40:39,137 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:40:39,137 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:40:39,137 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:40:39,137 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:40:39,137 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:40:39,137 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:40:39,137 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:40:39,137 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:40:39,137 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:40:39,140 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,142 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:40:39,142 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:40:39,142 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:40:39,143 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,143 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:40:39,143 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:40:39,137 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:40:39,137 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:40:39,144 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:40:39,144 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,144 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:40:39,137 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:40:39,137 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,145 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,146 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,146 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,146 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,145 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,147 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,147 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,147 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,147 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,147 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,147 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,148 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,148 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,148 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,146 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,146 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,147 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,148 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,148 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,148 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,148 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,149 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,149 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,149 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,149 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,150 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:40:39,150 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:40:39,150 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:40:39,150 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:40:39,150 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:40:39,150 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:40:39,147 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,153 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:40:39,153 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,153 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,153 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:40:39,153 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)
2022-03-15T00:40:39,154 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - RuntimeError: PytorchStreamReader failed locating file constants.pkl: file not found
2022-03-15T00:40:39,153 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,153 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,154 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,154 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,154 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,154 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,154 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:40:39,137 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,137 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,154 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:40:39,154 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:40:39,154 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:40:39,154 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:40:39,154 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:40:39,154 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:40:39,154 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:40:39,154 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:40:39,154 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,154 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,154 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,154 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,155 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,155 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,155 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,155 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:40:39,155 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,155 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:40:39,155 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:40:39,155 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:40:39,155 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:40:39,155 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:40:39,155 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:40:39,164 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239164
2022-03-15T00:40:39,164 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239164
2022-03-15T00:40:39,170 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,171 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239171
2022-03-15T00:40:39,171 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319239171
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,175 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,175 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,175 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,175 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,175 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,175 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:40:39,175 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,175 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,176 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,176 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,176 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,176 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:40:39,176 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:40:39,176 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:40:39,176 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:40:39,176 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:40:39,176 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:40:39,179 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,179 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:40:39,179 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:40:39,179 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:40:39,179 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:40:39,179 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,179 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:40:39,180 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,180 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:40:39,180 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,180 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:40:39,180 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:40:39,180 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:40:39,180 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:40:39,180 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:40:39,180 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:40:40,124 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:40:40,124 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:40:40,141 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:40:40,141 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:40:40,141 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:40:40,141 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:40:40,152 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:40:40,152 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:40:40,155 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:40:40,155 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:40:40,156 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:40:40,156 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:29,124 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:46:29,124 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:46:29,162 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:46:29,162 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:46:29,192 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315004040200-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:46:29,192 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315004040200-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:46:29,198 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315004040200-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319240201,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:46:29,198 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315004040200-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319240201,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:46:29,201 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315004040200-shutdown.cfg
2022-03-15T00:46:29,201 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315004040200-shutdown.cfg
2022-03-15T00:46:29,201 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315004040200-shutdown.cfg validated successfully
2022-03-15T00:46:29,201 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315004040200-shutdown.cfg validated successfully
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:29,314 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:46:29,314 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:46:29,314 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:46:29,320 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:46:29,320 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:46:29,321 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:46:29,320 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:46:29,321 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:46:29,321 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:46:29,321 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:29,321 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:46:29,321 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:46:29,320 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:46:29,321 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:46:29,320 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:46:29,321 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:46:29,321 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:46:29,321 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:29,320 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:46:29,322 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:46:29,322 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:46:29,437 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:46:29,437 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:46:29,437 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:46:29,437 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:46:29,446 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:46:29,446 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:46:29,447 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:46:29,447 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:46:29,454 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:46:29,454 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:46:29,882 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:46:29,882 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:46:29,924 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:29,925 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8486785888672|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:29,925 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.5830421447754|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:29,925 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:29,925 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2712.765625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:29,926 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5005.671875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:29,926 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319589
2022-03-15T00:46:30,793 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,793 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,793 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,793 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,793 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42565
2022-03-15T00:46:30,793 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,793 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,793 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42569
2022-03-15T00:46:30,794 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42571
2022-03-15T00:46:30,793 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,794 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42568
2022-03-15T00:46:30,793 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:30,794 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,793 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42570
2022-03-15T00:46:30,794 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,794 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42567
2022-03-15T00:46:30,794 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42566
2022-03-15T00:46:30,794 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42564
2022-03-15T00:46:30,794 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,794 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,794 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,794 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,794 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:30,794 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:30,794 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,795 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,795 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:30,796 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:46:30,796 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:46:30,796 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:46:30,796 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:46:30,796 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:46:30,796 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:46:30,796 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:46:30,796 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:46:30,796 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:46:30,796 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:46:30,796 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:46:30,796 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:46:30,796 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:46:30,796 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:46:30,796 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:46:30,796 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:46:30,832 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:46:30,832 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:46:30,832 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:46:30,832 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:46:30,832 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:46:30,832 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:46:30,833 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:46:30,832 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:46:30,833 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,833 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319590833
2022-03-15T00:46:30,877 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,879 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,881 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,882 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,882 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,883 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,886 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,887 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:30,920 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:30,920 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:30,921 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:30,922 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:30,922 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:46:30,923 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:46:30,923 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:46:30,923 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:46:30,923 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:46:30,923 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:46:30,923 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)
2022-03-15T00:46:30,924 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - RuntimeError: PytorchStreamReader failed locating file constants.pkl: file not found
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:30,924 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:30,924 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:30,924 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:30,926 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:30,926 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:30,926 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:30,926 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:30,926 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:30,926 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:30,924 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:30,931 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:30,931 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:30,931 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:30,931 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:30,932 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:30,932 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:30,932 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:30,932 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:30,932 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,933 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,933 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,935 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,935 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,937 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:30,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,938 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,938 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:30,938 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:30,938 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:30,938 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:30,938 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:30,939 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:30,939 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:30,939 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:30,932 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:30,937 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,984 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:30,984 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:30,985 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:30,985 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:30,985 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:30,985 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,932 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:30,989 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,989 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,937 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:30,937 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,001 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,001 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,001 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,001 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:30,938 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:30,938 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,002 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,002 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:30,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:30,937 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,002 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,002 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,002 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,002 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:31,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:31,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,003 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:30,938 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,003 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:30,938 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,003 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,004 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,004 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,000 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,004 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,000 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,004 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,004 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,004 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,004 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,002 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,002 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,006 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:46:31,006 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:46:31,006 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:46:31,006 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:46:31,007 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:31,007 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:46:31,005 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:46:31,005 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:46:31,007 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:46:31,007 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:46:31,007 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:46:31,007 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:46:31,007 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:46:31,007 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:46:31,007 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:46:31,009 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:46:31,009 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:46:31,004 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,010 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:46:31,010 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:46:31,011 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:31,011 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:46:31,018 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:46:31,018 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:46:31,018 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:46:31,018 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:46:31,007 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:46:30,971 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,019 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:46:31,006 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:31,019 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:46:31,018 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:46:31,018 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:31,019 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:46:31,019 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:31,019 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:46:31,019 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:46:31,019 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:31,019 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:46:31,020 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:31,006 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:46:30,971 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,020 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,019 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:46:31,019 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:46:31,011 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:46:31,011 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:46:31,019 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:46:31,020 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,020 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:46:31,020 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:46:31,020 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,020 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,020 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:46:31,020 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:46:30,946 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:30,946 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:31,026 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:46:31,026 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:46:31,026 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:46:31,026 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:46:31,026 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,026 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:31,027 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,027 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:31,027 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:46:31,027 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,027 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:31,027 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:46:31,027 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:46:31,027 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:46:31,027 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:46:31,027 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:46:31,027 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:46:31,027 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:46:31,027 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:46:31,027 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:46:31,027 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:46:31,027 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:46:31,032 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:31,032 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:46:31,032 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:46:31,032 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:31,032 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:46:31,032 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:46:31,033 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:31,033 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:46:31,033 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:46:31,033 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:31,033 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:46:31,033 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:46:31,034 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:31,034 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:46:31,034 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:46:37,211 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:46:37,211 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:46:37,243 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:46:37,243 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:46:37,269 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315004631276-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:46:37,269 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315004631276-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:46:37,272 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315004631276-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319591276,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:46:37,272 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315004631276-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319591276,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:46:37,275 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315004631276-shutdown.cfg
2022-03-15T00:46:37,275 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315004631276-shutdown.cfg
2022-03-15T00:46:37,276 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315004631276-shutdown.cfg validated successfully
2022-03-15T00:46:37,276 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315004631276-shutdown.cfg validated successfully
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:46:37,383 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:46:37,383 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:46:37,383 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:46:37,388 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:46:37,388 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:46:37,388 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:46:37,388 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:46:37,388 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:46:37,388 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:46:37,388 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:46:37,388 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:46:37,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:46:37,389 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:46:37,388 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:46:37,389 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:46:37,389 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:46:37,389 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:37,389 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:37,388 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:46:37,415 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:46:37,415 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:46:37,673 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:46:37,673 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:46:37,673 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:46:37,673 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:46:37,755 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:46:37,755 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:46:37,765 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:46:37,765 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:46:37,775 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:46:37,775 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:46:38,226 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:46:38,226 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8472023010254|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.5845184326172|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2715.984375|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5035.046875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,265 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647319598
2022-03-15T00:46:38,596 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,596 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42597
2022-03-15T00:46:38,597 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,597 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,597 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,597 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,599 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,600 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42598
2022-03-15T00:46:38,600 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,600 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,600 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:46:38,600 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:46:38,600 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,600 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,600 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:46:38,600 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:46:38,624 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,626 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,627 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,634 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42599
2022-03-15T00:46:38,635 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,635 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,635 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:46:38,634 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42604
2022-03-15T00:46:38,636 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:46:38,636 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,636 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,634 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42603
2022-03-15T00:46:38,636 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,636 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,636 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,636 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,636 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:46:38,636 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,636 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,636 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:46:38,636 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,637 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:46:38,637 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:46:38,636 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,637 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:46:38,637 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:46:38,638 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598638
2022-03-15T00:46:38,638 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598638
2022-03-15T00:46:38,638 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598638
2022-03-15T00:46:38,638 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598638
2022-03-15T00:46:38,665 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,665 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,665 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:46:38,666 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598666
2022-03-15T00:46:38,666 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598666
2022-03-15T00:46:38,665 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:46:38,665 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:46:38,665 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,666 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42600
2022-03-15T00:46:38,667 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598667
2022-03-15T00:46:38,667 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598667
2022-03-15T00:46:38,667 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,667 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,666 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598666
2022-03-15T00:46:38,666 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598666
2022-03-15T00:46:38,668 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,668 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,668 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:46:38,668 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:46:38,668 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,668 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42601
2022-03-15T00:46:38,668 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,668 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,669 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,669 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,669 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:46:38,669 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:46:38,672 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,672 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,672 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,672 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,673 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,673 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,673 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,673 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,673 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,684 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:46:38,684 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,685 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,684 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:46:38,687 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598687
2022-03-15T00:46:38,687 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,684 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,687 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598687
2022-03-15T00:46:38,687 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42602
2022-03-15T00:46:38,688 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,686 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,689 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,690 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,690 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,686 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,691 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,690 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,693 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,693 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,688 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:46:38,715 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,715 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,728 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,698 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,688 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:46:38,749 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:46:38,697 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,688 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,690 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,750 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,750 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,750 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,736 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,750 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,750 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:46:38,750 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)
2022-03-15T00:46:38,751 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - RuntimeError: PytorchStreamReader failed locating file constants.pkl: file not found
2022-03-15T00:46:38,749 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:46:38,749 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,752 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,752 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,752 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,728 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,697 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,715 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,753 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,753 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,698 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,753 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,753 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,715 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,754 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,754 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,750 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,715 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,755 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,755 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,744 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:46:38,714 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,755 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,756 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,750 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:46:38,760 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,760 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,760 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598760
2022-03-15T00:46:38,760 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598760
2022-03-15T00:46:38,760 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,761 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,761 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,762 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,783 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:46:38,789 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598788
2022-03-15T00:46:38,789 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647319598788
2022-03-15T00:46:38,790 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,799 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,800 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:46:38,800 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,803 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,803 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:46:38,803 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,751 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,751 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,808 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,808 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,808 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,808 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,753 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,753 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,809 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,809 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,809 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,809 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,753 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,753 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,809 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,809 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,809 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,809 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,809 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,810 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,810 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,810 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,753 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,753 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,811 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,811 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,811 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,811 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,812 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:46:38,812 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:46:38,812 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:46:38,812 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:46:38,813 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:46:38,813 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:46:38,813 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:46:38,814 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,754 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,814 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:46:38,755 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,816 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,821 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:46:38,821 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:46:38,821 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:46:38,821 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:46:38,821 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:46:38,813 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:46:38,828 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:46:38,821 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:46:38,821 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:46:38,821 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,817 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,830 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:46:38,816 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:46:38,821 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,821 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:46:38,821 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:46:38,755 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,830 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:46:38,830 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,831 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,814 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:46:38,831 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:46:38,831 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:46:38,831 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:46:38,831 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:46:38,814 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,832 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,813 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:46:38,832 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,829 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:46:38,832 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,832 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,813 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:46:38,832 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:46:38,832 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:46:38,832 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:46:38,830 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:46:38,830 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:46:38,832 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:46:38,832 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,832 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,754 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:46:38,826 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,832 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,833 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,829 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:46:38,832 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:46:38,831 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,833 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,832 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:46:38,833 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,833 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:46:38,833 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:46:38,832 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:46:38,832 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,832 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,833 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:46:38,833 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:46:38,833 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:46:38,833 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:46:38,833 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:46:38,832 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,832 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:46:38,833 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:46:38,833 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:46:38,834 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:46:38,834 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:46:38,834 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:46:38,832 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:46:38,834 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:46:38,834 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:46:38,834 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:46:38,834 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:46:38,833 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:46:38,834 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     cpp_module = torch._C.import_ir_module(cu, str(f), map_location, _extra_files)
2022-03-15T00:46:38,834 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - RuntimeError: PytorchStreamReader failed locating file constants.pkl: file not found
2022-03-15T00:46:38,833 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:46:38,833 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:46:38,834 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,834 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,833 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,833 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:46:38,833 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:46:38,834 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:46:38,834 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:46:38,834 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:46:38,835 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:46:38,835 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:46:38,835 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:46:38,835 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:46:38,833 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:46:38,835 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:46:38,835 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:46:38,835 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:46:38,833 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:46:38,835 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:46:38,835 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:46:38,833 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:46:38,835 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:46:38,835 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:46:38,836 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:46:38,836 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:46:38,836 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:46:38,836 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:46:38,836 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:46:38,834 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,834 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:46:38,836 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:46:38,836 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:46:38,836 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:46:38,836 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:46:38,836 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:46:38,836 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:46:38,837 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:46:38,837 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:46:38,837 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:46:38,835 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:46:39,826 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:39,826 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:46:39,834 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:46:39,834 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:46:39,834 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:46:39,834 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:46:39,834 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:46:39,834 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:46:39,834 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:46:39,834 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:46:39,836 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:46:39,836 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:46:39,836 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:46:39,836 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:46:39,838 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:46:39,838 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:53:52,114 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:53:52,114 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-03-15T00:53:52,156 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:53:52,156 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-03-15T00:53:52,190 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315004640751-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:53:52,190 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages
Current directory: /Users/changruimeng/Workspace/MovieRecommendation
Temp directory: /var/folders/dt/rjg6m6f945l3ydcxjjy4bmbr0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4096 M
Python executable: /Users/changruimeng/miniforge3/envs/vision/bin/python
Config file: logs/config/20220315004640751-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Initial Models: movie_model.mar
Log dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Metrics dir: /Users/changruimeng/Workspace/MovieRecommendation/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/changruimeng/Workspace/MovieRecommendation/model_store
Model config: N/A
2022-03-15T00:53:52,196 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315004640751-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319600751,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:53:52,196 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220315004640751-shutdown.cfg",
  "modelCount": 1,
  "created": 1647319600751,
  "models": {
    "movie_model": {
      "1.0": {
        "defaultVersion": true,
        "marName": "movie_model.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-03-15T00:53:52,199 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315004640751-shutdown.cfg
2022-03-15T00:53:52,199 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220315004640751-shutdown.cfg
2022-03-15T00:53:52,200 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315004640751-shutdown.cfg validated successfully
2022-03-15T00:53:52,200 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220315004640751-shutdown.cfg validated successfully
2022-03-15T00:53:52,310 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:53:52,310 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model movie_model
2022-03-15T00:53:52,310 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:53:52,310 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:53:52,310 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:53:52,310 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model movie_model
2022-03-15T00:53:52,310 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:53:52,310 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model movie_model loaded.
2022-03-15T00:53:52,311 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:53:52,311 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: movie_model, count: 8
2022-03-15T00:53:52,317 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:53:52,317 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:53:52,317 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:53:52,317 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:53:52,317 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:53:52,317 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:53:52,317 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:53:52,317 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:53:52,318 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:53:52,318 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:53:52,319 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:53:52,319 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:53:52,320 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:53:52,320 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:53:52,324 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:53:52,324 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-03-15T00:53:52,328 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:53:52,328 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:53:52,453 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:53:52,453 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-03-15T00:53:52,454 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:53:52,454 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-03-15T00:53:52,466 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:53:52,466 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-03-15T00:53:52,466 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:53:52,466 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-03-15T00:53:52,468 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:53:52,468 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-03-15T00:53:52,899 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:53:52,899 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-03-15T00:53:52,950 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:52,953 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:223.8360710144043|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:52,954 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:236.59564971923828|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:52,954 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:51.4|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:52,954 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2691.296875|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:52,954 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5057.515625|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:52,954 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.6|#Level:Host|#hostname:Changs-MacBook-Pro.local,timestamp:1647320032
2022-03-15T00:53:53,745 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,746 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - [PID]42729
2022-03-15T00:53:53,746 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,746 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,746 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,746 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,746 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,746 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,746 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - [PID]42724
2022-03-15T00:53:53,746 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,746 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,747 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,747 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,746 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - [PID]42726
2022-03-15T00:53:53,747 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,746 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - [PID]42725
2022-03-15T00:53:53,745 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,747 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,747 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Listening on port: None
2022-03-15T00:53:53,747 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - [PID]42727
2022-03-15T00:53:53,747 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - [PID]42723
2022-03-15T00:53:53,747 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,747 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,747 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,747 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,748 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,747 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - [PID]42728
2022-03-15T00:53:53,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,747 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - [PID]42730
2022-03-15T00:53:53,748 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,747 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,747 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,748 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,748 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,748 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Torch worker started.
2022-03-15T00:53:53,748 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,748 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,748 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,747 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change null -> WORKER_STARTED
2022-03-15T00:53:53,748 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,748 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Python runtime: 3.9.7
2022-03-15T00:53:53,749 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:53:53,749 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:53:53,749 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:53:53,749 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-03-15T00:53:53,749 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:53:53,749 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-03-15T00:53:53,749 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:53:53,749 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-03-15T00:53:53,749 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-03-15T00:53:53,749 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:53:53,750 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:53:53,749 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-03-15T00:53:53,750 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-03-15T00:53:53,749 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:53:53,749 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-03-15T00:53:53,749 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-03-15T00:53:53,788 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-03-15T00:53:53,789 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-03-15T00:53:53,789 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-03-15T00:53:53,789 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-03-15T00:53:53,790 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-03-15T00:53:53,790 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-03-15T00:53:53,790 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-03-15T00:53:53,790 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-03-15T00:53:53,791 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,791 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1647320033791
2022-03-15T00:53:53,826 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,826 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,826 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,831 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,831 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,831 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,831 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,831 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - model_name: movie_model, batchSize: 1
2022-03-15T00:53:53,873 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,874 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,873 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,873 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,874 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,874 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,874 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,874 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,874 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,874 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,874 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:53:53,875 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:53:53,875 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:53:53,876 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:53:53,875 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:53:53,874 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,874 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:53:53,875 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,874 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Backend worker process died.
2022-03-15T00:53:53,884 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,884 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,884 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,884 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,884 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:53:53,884 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:53:53,884 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:53:53,884 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:53:53,874 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,889 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,889 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,895 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,895 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,899 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,899 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,907 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,907 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,884 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:53:53,935 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:53:53,935 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:53:53,935 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:53:53,935 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:53:53,936 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,936 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,886 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,886 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,937 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,937 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,937 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,938 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,938 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,941 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,941 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,937 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,952 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,952 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,952 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,952 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,967 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,967 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,967 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,967 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,967 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,967 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,971 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,971 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,971 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,971 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,971 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,971 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,971 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:53:53,971 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:53:53,971 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stderr
2022-03-15T00:53:53,971 [INFO ] W-9007-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stderr
2022-03-15T00:53:53,971 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,971 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,971 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:53:53,971 [WARN ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-movie_model_1.0-stdout
2022-03-15T00:53:53,972 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:53:53,972 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stderr
2022-03-15T00:53:53,972 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:53:53,972 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:53:53,972 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:53:53,972 [WARN ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-movie_model_1.0-stdout
2022-03-15T00:53:53,972 [INFO ] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-03-15T00:53:53,972 [INFO ] W-9001-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stderr
2022-03-15T00:53:53,972 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:53:53,972 [INFO ] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-03-15T00:53:53,953 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,953 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,977 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,977 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,978 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,978 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,978 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,978 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,979 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:53:53,979 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stderr
2022-03-15T00:53:53,979 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:53:53,979 [WARN ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-movie_model_1.0-stdout
2022-03-15T00:53:53,979 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:53:53,979 [INFO ] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-03-15T00:53:53,980 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,980 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-03-15T00:53:53,980 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,980 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-03-15T00:53:53,981 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,981 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,979 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:53:53,981 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,979 [INFO ] W-9006-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stderr
2022-03-15T00:53:53,981 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,981 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,981 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,983 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:53:53,983 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:53:53,983 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stderr
2022-03-15T00:53:53,983 [INFO ] W-9000-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stderr
2022-03-15T00:53:53,983 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:53:53,983 [WARN ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-movie_model_1.0-stdout
2022-03-15T00:53:53,984 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:53:53,984 [INFO ] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-03-15T00:53:53,990 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:53:53,990 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:53:53,990 [INFO ] W-9007-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:53:53,990 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:53:53,990 [INFO ] W-9007-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-movie_model_1.0-stdout
2022-03-15T00:53:53,990 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:53:53,990 [INFO ] W-9000-movie_model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-03-15T00:53:53,990 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:53:53,990 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-03-15T00:53:53,990 [INFO ] W-9006-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-03-15T00:53:53,991 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:53:53,991 [INFO ] W-9006-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-movie_model_1.0-stdout
2022-03-15T00:53:53,990 [INFO ] W-9000-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-movie_model_1.0-stdout
2022-03-15T00:53:53,895 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,938 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,938 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,938 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,994 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,994 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,994 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,994 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,938 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,995 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,995 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,995 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,995 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,895 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,995 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,995 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,995 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,995 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 85, in initialize
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     self.model = self._load_torchscript_model(model_pt_path)
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 109, in _load_torchscript_model
2022-03-15T00:53:53,995 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -     return torch.jit.load(model_pt_path, map_location=self.device)
2022-03-15T00:53:53,995 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stderr
2022-03-15T00:53:53,996 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:53:53,996 [WARN ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-movie_model_1.0-stdout
2022-03-15T00:53:53,996 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:53:53,995 [INFO ] W-9004-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:53:53,996 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     worker.run_server()
2022-03-15T00:53:53,996 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-03-15T00:53:53,996 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:53:53,996 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:53:53,995 [INFO ] W-9002-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stderr
2022-03-15T00:53:53,996 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:53:53,996 [INFO ] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-03-15T00:53:53,996 [WARN ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-movie_model_1.0-stdout
2022-03-15T00:53:53,997 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:53:53,907 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,996 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-03-15T00:53:53,997 [INFO ] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-03-15T00:53:53,995 [INFO ] W-9005-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stderr
2022-03-15T00:53:53,907 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-03-15T00:53:53,995 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stderr
2022-03-15T00:53:53,997 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,998 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:53:53,998 [WARN ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-movie_model_1.0-stdout
2022-03-15T00:53:53,998 [INFO ] W-9001-movie_model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-03-15T00:53:53,997 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: movie_model, error: Worker died.
2022-03-15T00:53:53,998 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:53:53,998 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,998 [INFO ] W-9001-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-movie_model_1.0-stdout
2022-03-15T00:53:53,998 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-movie_model_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-03-15T00:53:53,998 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:53:53,998 [INFO ] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-03-15T00:53:53,998 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:53:53,998 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stderr
2022-03-15T00:53:53,999 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:53:53,998 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:53:53,999 [WARN ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-movie_model_1.0-stdout
2022-03-15T00:53:53,999 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:53:53,999 [INFO ] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-03-15T00:53:53,998 [INFO ] W-9003-movie_model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stderr
2022-03-15T00:53:53,999 [INFO ] W-9002-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:53:53,999 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:53:53,999 [INFO ] W-9002-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-movie_model_1.0-stdout
2022-03-15T00:53:54,000 [INFO ] W-9005-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/torch/jit/_serialization.py", line 161, in load
2022-03-15T00:53:54,000 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:53:54,000 [INFO ] W-9005-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-movie_model_1.0-stdout
2022-03-15T00:53:54,000 [INFO ] W-9003-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-03-15T00:53:54,000 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:53:54,000 [INFO ] W-9003-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-movie_model_1.0-stdout
2022-03-15T00:53:54,006 [INFO ] W-9004-movie_model_1.0-stdout MODEL_LOG -   File "/Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-03-15T00:53:54,006 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:53:54,006 [INFO ] W-9004-movie_model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-movie_model_1.0-stdout
2022-03-15T00:53:54,980 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:53:54,980 [DEBUG] W-9001-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-03-15T00:53:54,982 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:53:54,982 [DEBUG] W-9007-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-03-15T00:53:54,982 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:53:54,982 [DEBUG] W-9006-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-03-15T00:53:54,985 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:53:54,985 [DEBUG] W-9000-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-03-15T00:53:54,999 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:53:54,999 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-03-15T00:53:54,999 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:53:54,999 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:53:54,999 [DEBUG] W-9003-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-03-15T00:53:54,999 [DEBUG] W-9002-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-03-15T00:53:54,999 [DEBUG] W-9005-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-03-15T00:53:54,999 [DEBUG] W-9004-movie_model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/changruimeng/miniforge3/envs/vision/bin/python, /Users/changruimeng/miniforge3/envs/vision/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004]
